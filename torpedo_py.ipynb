{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "1x-C547VIMXgTApTKbngT_bg3NAIXLH4D",
      "authorship_tag": "ABX9TyNlfl/dXtSKO83jndjQiMvM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fcohenriquez/torpedo_py/blob/main/torpedo_py.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lrwYLGxparQ4"
      },
      "source": [
        "#**Torpedo para trabajar datos con Python**\n",
        "\n",
        "En este cuaderno se deja un torpedo con comandos utiles para trabajar principalmente bases de datos con python.\n",
        "Primero se importan las principales librerias con las que se trabaja (pandas y numpy). Tambien se carga un par de datasets donde probar los ejemplos que se entregan (data de pydataset)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YvDlMZWPDiQu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab47565a-764b-4ca3-e38c-ab29463717f2"
      },
      "source": [
        "pip install pydataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pydataset\n",
            "  Downloading pydataset-0.2.0.tar.gz (15.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 15.9 MB 303 kB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from pydataset) (1.3.5)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas->pydataset) (1.21.6)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->pydataset) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->pydataset) (2022.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->pydataset) (1.15.0)\n",
            "Building wheels for collected packages: pydataset\n",
            "  Building wheel for pydataset (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pydataset: filename=pydataset-0.2.0-py3-none-any.whl size=15939432 sha256=46adb0e67baf9bbe0ec92e00c2f6445286fab53586b5d7c61ee10c5f139ca365\n",
            "  Stored in directory: /root/.cache/pip/wheels/32/26/30/d71562a19eed948eaada9a61b4d722fa358657a3bfb5d151e2\n",
            "Successfully built pydataset\n",
            "Installing collected packages: pydataset\n",
            "Successfully installed pydataset-0.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ozdK8WOZZfg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac3e06ad-2b49-46df-872d-5a905d565210"
      },
      "source": [
        "from pydataset import data\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "print('setup ok')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "initiated datasets repo at: /root/.pydataset/\n",
            "setup ok\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iUSoX7W4bqMS"
      },
      "source": [
        "se cargan las bd iris y mtcars para ser trabajada como DF de pandas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sSLTq1x1ZduP"
      },
      "source": [
        "iris=data('iris')\n",
        "mtcars = data('mtcars')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C2PdlnCJvjMs",
        "outputId": "32c92798-18aa-44c9-eec5-d6cdbafb282e"
      },
      "source": [
        "# Tamaño del DF\n",
        "print(len(iris))\n",
        "print(len(mtcars))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "150\n",
            "32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o9ldfTfm3D5X"
      },
      "source": [
        "## Configuracion de python"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SzINlrSr3Iag"
      },
      "source": [
        "'''\n",
        "\n",
        "No ejecutar esta parte\n",
        "\n",
        "# Fijar directorio\n",
        "import os\n",
        "os.chdir(\"D:/francisco.henriquez/Mis documentos/proyectos/asignacion_teorica/anlisis_2019\")\n",
        "\n",
        "\n",
        "\n",
        "#modificar opciones de display\n",
        "\n",
        "pd.set_option('display.max_rows', 500)\n",
        "pd.set_option('display.max_columns', 500)\n",
        "pd.set_option('display.width', 1000)\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Objetos de Python"
      ],
      "metadata": {
        "id": "H9Dp4f3p4A7G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Listas"
      ],
      "metadata": {
        "id": "J_LtUjU3M3_q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lista vacia\n",
        "\n",
        "vacia=[]\n",
        "print(vacia)\n",
        "\n",
        "# Listas de elementos repetidos\n",
        "\n",
        "x=[True]*5\n",
        "print(x)\n",
        "\n",
        "# agregar elemento a una lista\n",
        "x=[1,2,3]\n",
        "print (x)\n",
        "x.append(99)\n",
        "x.append([4,5])\n",
        "print(x)\n",
        "\n",
        "# Sumar los elementos de mas de una lista\n",
        "y=[10,11,12,15]\n",
        "x1=x+y\n",
        "print(x1)\n",
        "\n",
        "# Llamar a un elemento de una lista\n",
        "print(x[0])\n",
        "print(x[-1])\n",
        "\n",
        "# Copiar una lista\n",
        "y=x.copy()\n",
        "print(y)\n",
        "\n",
        "# Invertir lista\n",
        "y.reverse()\n",
        "print(y)\n",
        "\n",
        "# Quitar y entregar un elemento de una lista\n",
        "z=y.pop(0)\n",
        "print(z)\n",
        "print(y)\n",
        "\n",
        "# ordenar elementos de una lista\n",
        "y.sort()\n",
        "print(y)\n",
        "\n",
        "# una serie de numeros\n",
        "\n",
        "c=list(range(6))\n",
        "print(c)\n",
        "\n",
        "c=list(range(3,10,2))\n",
        "print(c)\n",
        "\n",
        "#los string pueden ser considerados como listas\n",
        "s=\"hola\"\n",
        "print(s)\n",
        "print(s[1])\n",
        "\n",
        "# quitar duplicados de una lista. Los set no pueden contener elemntos duplicados\n",
        "\n",
        "d=[2,2,1,3,4,6,8,6,4]\n",
        "print(d)\n",
        "d=list(set(d))\n",
        "print(d)\n",
        "\n",
        "\n",
        "# Multiplicar o sumar todos los elementos de una lista por un escalar\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "m=[1,2,3,4]\n",
        "m2=list(np.array(m)*3)\n",
        "ms2=list(np.array(m)+3)\n",
        "m3=[i*3 for i in m]\n",
        "ms3=[i+3 for i in m]\n",
        "print(m,m2, m3, ms2, ms3)\n",
        "\n",
        "\n",
        "# https://docs.python.org/es/3/tutorial/datastructures.html\n",
        "\n",
        "\n",
        "#https://note.nkmk.me/en/python-list-clear-pop-remove-del/\n",
        "#https://note.nkmk.me/en/python-list-select-replace/\n",
        "# https://note.nkmk.me/en/python-list-comprehension/\n",
        "\n",
        "\n",
        "# len(x) cuenta los elmentos de una lista x\n",
        "\n",
        "# Funciones sobre strings\n",
        "\n",
        "#https://docs.python.org/3/library/stdtypes.html#string-methods\n",
        "\n",
        "# s.count(x) cuenta las apariciones de x en s\n",
        "# s.find(x) retorna la posicion de x en s\n",
        "# s.replace(x,y) reemplaza x por y en el string s\n",
        "# s.upper() transforma todos los carateres del string a mayuscula\n",
        "# s.lower() transforma todos los carateres del string a minuscula\n",
        "# s.strip() remueve los espacios y otros similares al comienzo y final del string\n",
        "# s.split(\",\") divide el string s por , y convierte los elementos en una lista\n",
        "# s.isalpha() verifica si el string s contiene únicamente caracteres alfabéticos (letras) y no está vacía.\n",
        "# s.isalnum() verifica si el string s contiene únicamente caracteres alfanumericos y no está vacía.\n",
        "# c.isdecimal(), c.isdigit(), or c.isnumeric() son parecidos\n",
        "# s.endswith('e')\n",
        "\n",
        "#Funciones generales\n",
        "# l[i:j] entrega los elementos entre i y j-1 de la lista l\n",
        "\n",
        "# l.remove(x) elimina el primer elemento x de la lista l\n",
        "# l.pop(x) elimina el elemento en la posicion x de la lista l y mantener ese valor (y=l.pop(x))- pop() elimina el ultimo elemento\n",
        "# l.clear() elimina todos los elementos de la lista l\n",
        "# con del l[i:j] se puede eliminar slices. l[:] es equivalente a l.clear()\n",
        "# l.append(x) agrega el elemento x a la lista l\n",
        "# l.extend(m) Agrega los elementos de la lista m al final de la lista l. Equivalente a [1,2]+[3,4]\n",
        "# l.count(x) cuenta la veces que aparece el elmento x en l\n",
        "# l.index(x) Retorna el índice de la primera vez que el  elemento x se encuentra dentro de l. Sino se  encuentra, genera un error\n",
        "# l.sot() ordena los elementos de l\n",
        "# del(l[n]) Elimina el elemento 0 de la lista l\n",
        "# l.split(\"#\") igual que strings\n",
        "# B=A[:] B es un clon de A, pero que no es la misma (no tiene pointer)\n",
        "# l.count(x) cuenta el numero de veces que x aparece en l\n",
        "\n",
        "# Iterar ebn lista\n",
        "# for i in lista:  Itera sobre los elementos en lista\n",
        "\n",
        "# list comprehension\n",
        "# [expression for variable_name in iterable if condition]\n",
        "# l = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
        "# evens = [i for i in l if i % 2 == 0]\n",
        "#[(X if condition else Y) for variable_name in original_list]\n",
        "# l_sub = [i2 - i1 for i1, i2 in zip(l_int1, l_int2)] Con zip se puede hacer operaciones con multiples listas\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M40wlO5YM6Li",
        "outputId": "4fd5aaca-9955-4305-90a5-67a995f3ecc4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[]\n",
            "[True, True, True, True, True]\n",
            "[1, 2, 3]\n",
            "[1, 2, 3, 99, [4, 5]]\n",
            "[1, 2, 3, 99, [4, 5], 10, 11, 12, 15]\n",
            "1\n",
            "[4, 5]\n",
            "[1, 2, 3, 99, [4, 5]]\n",
            "[[4, 5], 99, 3, 2, 1]\n",
            "[4, 5]\n",
            "[99, 3, 2, 1]\n",
            "[1, 2, 3, 99]\n",
            "[0, 1, 2, 3, 4, 5]\n",
            "[3, 5, 7, 9]\n",
            "hola\n",
            "o\n",
            "[2, 2, 1, 3, 4, 6, 8, 6, 4]\n",
            "[1, 2, 3, 4, 6, 8]\n",
            "[1, 2, 3, 4] [3, 6, 9, 12] [3, 6, 9, 12] [4, 5, 6, 7] [4, 5, 6, 7]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####lambda, map, filter, reduce, zip"
      ],
      "metadata": {
        "id": "SnxrS1FoVJH5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# lambda es una fuuncion anonima que usa multiples parametros y una unica expresion\n",
        "add=lambda a,b,c: print(a+b+c)\n",
        "print(add(4, 5, 1))\n",
        "\n",
        "# Map aplica una función a cada uno de los elementos de una lista\n",
        "x=[1,2,3,4,5]\n",
        "\n",
        "def cuadrado(i):\n",
        "  return(i**2)\n",
        "\n",
        "x2=list(map(cuadrado, x))\n",
        "\n",
        "x3=list(map(lambda i:i**3, x))\n",
        "\n",
        "print(x, x2, x3)\n",
        "\n",
        "# filter  filtra una lista de elementos para los que una función devuelve True\n",
        "\n",
        "valores = [1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
        "pares = list(filter(lambda x : x % 2 == 0, valores))\n",
        "print(valores, pares)\n",
        "\n",
        "# reduce se utiliza para llevar a cabo un cálculo acumulativo sobre una lista de valores y devolver el resultado.\n",
        "\n",
        "from functools import reduce\n",
        "\n",
        "seq=[2,3,4,5,6]\n",
        "multiply=reduce(lambda a,b:a*b,seq)\n",
        "print(seq, multiply)\n",
        "\n",
        "\n",
        "# zip devuelve un conjuto de n tuplas que toman combinan los n elementos de las listas que se le entrega\n",
        "\n",
        "\n",
        "name = [\"Manjeet\", \"Nikhil\", \"Shambhavi\"]\n",
        "roll_no = [4, 1, 3]\n",
        "marks = [40, 50, 60]\n",
        "\n",
        "mapped = zip(name, roll_no, marks)\n",
        "\n",
        "print(list(mapped))\n",
        "\n",
        "\n",
        "name = [\"Manjeet\", \"Nikhil\", \"Shambhavi\"]\n",
        "marks = [[40,34], 50, 60]\n",
        "\n",
        "mapped = zip(name, marks)\n",
        "\n",
        "print(dict(mapped))\n",
        "\n",
        "# https://j2logo.com/python/funciones-lambda-en-python/\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W3gT0enUVN_R",
        "outputId": "f605dd07-1f97-4c45-f919-aa65fc54df64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10\n",
            "None\n",
            "[1, 2, 3, 4, 5] [1, 4, 9, 16, 25] [1, 8, 27, 64, 125]\n",
            "[1, 2, 3, 4, 5, 6, 7, 8, 9] [2, 4, 6, 8]\n",
            "[2, 3, 4, 5, 6] 720\n",
            "[('Manjeet', 4, 40), ('Nikhil', 1, 50), ('Shambhavi', 3, 60)]\n",
            "{'Manjeet': [40, 34], 'Nikhil': 50, 'Shambhavi': 60}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Diccionarios"
      ],
      "metadata": {
        "id": "f2eRcDfdkd_B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Diccionarios"
      ],
      "metadata": {
        "id": "lWIU7RQcktwY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Iteraciones"
      ],
      "metadata": {
        "id": "I60A5mb6kvmQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# For loops\n",
        "for e in [1,2,3]:\n",
        "    print(e+5)\n",
        "\n",
        "for _ in range(10):\n",
        "  print(_)\n",
        "\n",
        "print([a*10 for a in range(20)])\n",
        "\n",
        "diccionario = {\"a\": 1, \"b\": 2, \"c\": 3}\n",
        "conjunto = {\"A\", \"B\", \"C\", \"D\"}\n",
        "rango = range(100, 110)\n",
        "for clave in diccionario:\n",
        "    print(clave)\n",
        "for elemento in conjunto:\n",
        "    print(elemento)\n",
        "for numero in rango:\n",
        "    print(numero)\n",
        "\n",
        "\n",
        "# While\n",
        "n=0\n",
        "while n <6:\n",
        "  print(n)\n",
        "  n += 1\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bm0a9NmIk0uI",
        "outputId": "2f12beba-0096-48a3-99f1-eaba42adc6d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6\n",
            "7\n",
            "8\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "[0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150, 160, 170, 180, 190]\n",
            "a\n",
            "b\n",
            "c\n",
            "B\n",
            "D\n",
            "C\n",
            "A\n",
            "100\n",
            "101\n",
            "102\n",
            "103\n",
            "104\n",
            "105\n",
            "106\n",
            "107\n",
            "108\n",
            "109\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Operadores"
      ],
      "metadata": {
        "id": "fM9qie9vq9QH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "+\n",
        "-\n",
        "*\n",
        "/\n",
        "// division entera\n",
        "% resto de la division\n",
        "\n",
        "** exponente\n",
        "\n",
        "()\n",
        "==\n",
        ">\n",
        "<\n",
        ">=\n",
        "<=\n",
        "!=\n",
        "\n",
        "~ not\n",
        "| or\n",
        "^ xor (o exclusivo)\n",
        "& and\n",
        "\n",
        "+=, -=, *=, /= ,%=, //=, **=, &=, |=, ^=\n",
        "\n",
        "is retorna True si dos elementos apuntan al mismo objeto\n",
        "is not\n",
        "\n",
        "in retorna True si el valor/varuable esta en la secuencia\n",
        "not in\n"
      ],
      "metadata": {
        "id": "2JOLsGOUrBhG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a=1\n",
        "b=1\n",
        "print('a b')\n",
        "for _ in range(5):\n",
        "  print(a, b)\n",
        "  a+=2\n",
        "  b*=2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ECAPW3mytUNm",
        "outputId": "0b362944-0c89-48c0-8f9c-ed85ece4ef8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a b\n",
            "1 1\n",
            "3 2\n",
            "5 4\n",
            "7 8\n",
            "9 16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Importar, generar y exportar DataFrames"
      ],
      "metadata": {
        "id": "-1R0EXY94wYa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importar dataframe"
      ],
      "metadata": {
        "id": "xRdR9hhU5qZo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Importar datos\n",
        "\n",
        "raw_df = pd.read_csv('https://storage.googleapis.com/download.tensorflow.org/data/creditcard.csv') # En este caso, se importa de una pagina web. Se puede importar del disco local en el que se esta trabajando\n",
        "\n",
        "print(raw_df.head())\n",
        "\n",
        "'''\n",
        "df_herencia=pd.read_stata('DFL2_Herencia_2018.dta') # Importar datos de stata\n",
        "\n",
        "roles_elim=pd.read_csv(\"excluidos_2017_sem2.txt\", sep='|',\n",
        "         dtype={'comuna_act':str, 'manzana':str, 'predio':str}, encoding='iso-8859-1')\n",
        "\n",
        "\n",
        "pru=pd.read_excel('gk_5000.xlsx', sheet_name='muestra_2021',  engine='openpyxl')\n",
        "\n",
        "\n",
        "#  importar con pd.read_parquet\n",
        "pd.read_parquet('example_pa.parquet', engine='pyarrow', columns=[a,b,c])\n",
        "# Importar en formato feather\n",
        "pd.read_feather\n",
        "\n",
        "'''\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "IAo64KoH47dA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exportar dataframe"
      ],
      "metadata": {
        "id": "7pkB4--t50t6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "# Guardar y cargar en formato pickle\n",
        "\n",
        "libro_socios_solo_finales.to_pickle('libro_socios_solo_finales.pkl')\n",
        "mat_N_data =pd.read_pickle('datos_mat_N.pkl')\n",
        "\n",
        "# Exportar a csv y excel\n",
        "\n",
        "part_final.to_csv(\"part_final_py.csv\", sep='\\t', index=False)\n",
        "df_vec_renta.to_excel(\"vectores_rta_nombres.xlsx\", index=False)\n",
        "\n",
        "#Multiples hojas o en la misma hoja, cambiando la celda start\n",
        "writer = pd.ExcelWriter('resumen_ing_norenta.xlsx', engine='xlsxwriter')\n",
        "res_agr.to_excel(writer, sheet_name='decil', index=True, startrow=1, startcol=1)\n",
        "res_agr_tgc.to_excel(writer, sheet_name='tramo', index=True, startrow=1, startcol=1)\n",
        "writer.save()\n",
        "\n",
        "# Exportar en formato parquet\n",
        "\n",
        "df.to_parquet('df.parquet.gzip', compression='gzip') # se puede indicar el tipo de compresion\n",
        "\n",
        "# Exportar en formate feather\n",
        "df.to_feather\n",
        "\n",
        "\n",
        "'''\n"
      ],
      "metadata": {
        "id": "uNBMzK8I55mv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NytMHQMXbxYi"
      },
      "source": [
        "## Comandos para realizar exploracion inicial del DF"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MmrDb008x_vM"
      },
      "source": [
        "### Nombres y tipos de variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NcrYpfja2Os_",
        "outputId": "dbbe8fc6-04c0-4a59-9657-eb92ccf20db7"
      },
      "source": [
        "# nombre de columnas\n",
        "\n",
        "print(list(mtcars.columns))\n",
        "\n",
        "# Tipos de variables\n",
        "\n",
        "print(mtcars.dtypes)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['mpg', 'cyl', 'disp', 'hp', 'drat', 'wt', 'qsec', 'vs', 'am', 'gear', 'carb']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DYjIjesgxqxc"
      },
      "source": [
        "###Head y tail"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "j1dKcrTnZh82",
        "outputId": "5bb90c45-ac8b-4a81-a399-935f8912397f"
      },
      "source": [
        "# .head(n) muestra las primeras n filas del DF. Por defecto es n=5\n",
        "iris.head(4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sepal.Length</th>\n",
              "      <th>Sepal.Width</th>\n",
              "      <th>Petal.Length</th>\n",
              "      <th>Petal.Width</th>\n",
              "      <th>Species</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Sepal.Length  Sepal.Width  Petal.Length  Petal.Width Species\n",
              "1           5.1          3.5           1.4          0.2  setosa\n",
              "2           4.9          3.0           1.4          0.2  setosa\n",
              "3           4.7          3.2           1.3          0.2  setosa\n",
              "4           4.6          3.1           1.5          0.2  setosa"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ukn4Y7kcRfC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "9859bf9a-5694-4868-aa40-71d636e5e482"
      },
      "source": [
        "# .tail(n) muestra las ultimas n filas del DF. Por defecto es n=5\n",
        "mtcars.tail()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mpg</th>\n",
              "      <th>cyl</th>\n",
              "      <th>disp</th>\n",
              "      <th>hp</th>\n",
              "      <th>drat</th>\n",
              "      <th>wt</th>\n",
              "      <th>qsec</th>\n",
              "      <th>vs</th>\n",
              "      <th>am</th>\n",
              "      <th>gear</th>\n",
              "      <th>carb</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Lotus Europa</th>\n",
              "      <td>30.4</td>\n",
              "      <td>4</td>\n",
              "      <td>95.1</td>\n",
              "      <td>113</td>\n",
              "      <td>3.77</td>\n",
              "      <td>1.513</td>\n",
              "      <td>16.9</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Ford Pantera L</th>\n",
              "      <td>15.8</td>\n",
              "      <td>8</td>\n",
              "      <td>351.0</td>\n",
              "      <td>264</td>\n",
              "      <td>4.22</td>\n",
              "      <td>3.170</td>\n",
              "      <td>14.5</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Ferrari Dino</th>\n",
              "      <td>19.7</td>\n",
              "      <td>6</td>\n",
              "      <td>145.0</td>\n",
              "      <td>175</td>\n",
              "      <td>3.62</td>\n",
              "      <td>2.770</td>\n",
              "      <td>15.5</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Maserati Bora</th>\n",
              "      <td>15.0</td>\n",
              "      <td>8</td>\n",
              "      <td>301.0</td>\n",
              "      <td>335</td>\n",
              "      <td>3.54</td>\n",
              "      <td>3.570</td>\n",
              "      <td>14.6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Volvo 142E</th>\n",
              "      <td>21.4</td>\n",
              "      <td>4</td>\n",
              "      <td>121.0</td>\n",
              "      <td>109</td>\n",
              "      <td>4.11</td>\n",
              "      <td>2.780</td>\n",
              "      <td>18.6</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 mpg  cyl   disp   hp  drat     wt  qsec  vs  am  gear  carb\n",
              "Lotus Europa    30.4    4   95.1  113  3.77  1.513  16.9   1   1     5     2\n",
              "Ford Pantera L  15.8    8  351.0  264  4.22  3.170  14.5   0   1     5     4\n",
              "Ferrari Dino    19.7    6  145.0  175  3.62  2.770  15.5   0   1     5     6\n",
              "Maserati Bora   15.0    8  301.0  335  3.54  3.570  14.6   0   1     5     8\n",
              "Volvo 142E      21.4    4  121.0  109  4.11  2.780  18.6   1   1     4     2"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8XOHrUAsxuF0"
      },
      "source": [
        "### Tabla de frecuencia y tabulación cruzada"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1D0fVYPgd2Ce",
        "outputId": "4dc82f61-9ecc-4062-aa8a-1f4987f69c0c"
      },
      "source": [
        "# Tabla de frecuencia\n",
        "print('una variable')\n",
        "print(mtcars['cyl'].value_counts(sort=False)) # Para una variable\n",
        "print('varias variables')\n",
        "print(mtcars.groupby(['cyl', 'gear', 'carb'], as_index=False).size()) # Para varias variables simultaneamente\n",
        "\n",
        "print('variable continuas')\n",
        "print(iris['Sepal.Length'].value_counts(bins=3)) # Para variables continuas"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "una variable\n",
            "4    11\n",
            "6     7\n",
            "8    14\n",
            "Name: cyl, dtype: int64\n",
            "varias variables\n",
            "    cyl  gear  carb  size\n",
            "0     4     3     1     1\n",
            "1     4     4     1     4\n",
            "2     4     4     2     4\n",
            "3     4     5     2     2\n",
            "4     6     3     1     2\n",
            "5     6     4     4     4\n",
            "6     6     5     6     1\n",
            "7     8     3     2     4\n",
            "8     8     3     3     3\n",
            "9     8     3     4     5\n",
            "10    8     5     4     1\n",
            "11    8     5     8     1\n",
            "variable continuas\n",
            "(5.5, 6.7]      71\n",
            "(4.295, 5.5]    59\n",
            "(6.7, 7.9]      20\n",
            "Name: Sepal.Length, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-mlL00w7r9ju",
        "outputId": "ee7d8b73-8cdc-46bc-d164-c9570a740a29"
      },
      "source": [
        "# Tabulacion cruzada\n",
        "\n",
        "print(pd.crosstab(mtcars['cyl'], mtcars['gear']))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gear   3  4  5\n",
            "cyl           \n",
            "4      1  8  2\n",
            "6      2  4  1\n",
            "8     12  0  2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RvnM8kLwx0-8"
      },
      "source": [
        "### Estadísticas descriptivas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rv0TiREKtm_e",
        "outputId": "71ea11e6-088c-497d-b9b0-aca07ea198a8"
      },
      "source": [
        "# Sumario de columnas\n",
        "\n",
        "print(iris.describe())\n",
        "\n",
        "perc=[0.01, 0.1, 0.9, 0.99] # Para personalizar los percentiles\n",
        "\n",
        "print(iris.describe(percentiles =perc))\n",
        "\n",
        "\n",
        "print(mtcars.dtypes)\n",
        "\n",
        "print(iris.info())\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       Sepal.Length  Sepal.Width  Petal.Length  Petal.Width\n",
            "count    150.000000   150.000000    150.000000   150.000000\n",
            "mean       5.843333     3.057333      3.758000     1.199333\n",
            "std        0.828066     0.435866      1.765298     0.762238\n",
            "min        4.300000     2.000000      1.000000     0.100000\n",
            "25%        5.100000     2.800000      1.600000     0.300000\n",
            "50%        5.800000     3.000000      4.350000     1.300000\n",
            "75%        6.400000     3.300000      5.100000     1.800000\n",
            "max        7.900000     4.400000      6.900000     2.500000\n",
            "       Sepal.Length  Sepal.Width  Petal.Length  Petal.Width\n",
            "count    150.000000   150.000000    150.000000   150.000000\n",
            "mean       5.843333     3.057333      3.758000     1.199333\n",
            "std        0.828066     0.435866      1.765298     0.762238\n",
            "min        4.300000     2.000000      1.000000     0.100000\n",
            "1%         4.400000     2.200000      1.149000     0.100000\n",
            "10%        4.800000     2.500000      1.400000     0.200000\n",
            "50%        5.800000     3.000000      4.350000     1.300000\n",
            "90%        6.900000     3.610000      5.800000     2.200000\n",
            "99%        7.700000     4.151000      6.700000     2.500000\n",
            "max        7.900000     4.400000      6.900000     2.500000\n",
            "mpg     float64\n",
            "cyl       int64\n",
            "disp    float64\n",
            "hp        int64\n",
            "drat    float64\n",
            "wt      float64\n",
            "qsec    float64\n",
            "vs        int64\n",
            "am        int64\n",
            "gear      int64\n",
            "carb      int64\n",
            "dtype: object\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 150 entries, 1 to 150\n",
            "Data columns (total 5 columns):\n",
            " #   Column        Non-Null Count  Dtype  \n",
            "---  ------        --------------  -----  \n",
            " 0   Sepal.Length  150 non-null    float64\n",
            " 1   Sepal.Width   150 non-null    float64\n",
            " 2   Petal.Length  150 non-null    float64\n",
            " 3   Petal.Width   150 non-null    float64\n",
            " 4   Species       150 non-null    object \n",
            "dtypes: float64(4), object(1)\n",
            "memory usage: 7.0+ KB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "LuSIuRU2ul0D",
        "outputId": "496836e4-8abb-4572-93d9-ef4cafb05257"
      },
      "source": [
        "# Para tener estadisticas descriptivas por una variable dada\n",
        "mtcars.groupby('cyl')['hp'].describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cyl</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11.0</td>\n",
              "      <td>82.636364</td>\n",
              "      <td>20.934530</td>\n",
              "      <td>52.0</td>\n",
              "      <td>65.50</td>\n",
              "      <td>91.0</td>\n",
              "      <td>96.00</td>\n",
              "      <td>113.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7.0</td>\n",
              "      <td>122.285714</td>\n",
              "      <td>24.260491</td>\n",
              "      <td>105.0</td>\n",
              "      <td>110.00</td>\n",
              "      <td>110.0</td>\n",
              "      <td>123.00</td>\n",
              "      <td>175.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>14.0</td>\n",
              "      <td>209.214286</td>\n",
              "      <td>50.976886</td>\n",
              "      <td>150.0</td>\n",
              "      <td>176.25</td>\n",
              "      <td>192.5</td>\n",
              "      <td>241.25</td>\n",
              "      <td>335.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     count        mean        std    min     25%    50%     75%    max\n",
              "cyl                                                                   \n",
              "4     11.0   82.636364  20.934530   52.0   65.50   91.0   96.00  113.0\n",
              "6      7.0  122.285714  24.260491  105.0  110.00  110.0  123.00  175.0\n",
              "8     14.0  209.214286  50.976886  150.0  176.25  192.5  241.25  335.0"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qg8EEBc_yEb9"
      },
      "source": [
        "### Top n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ujqs_Y_DvHil",
        "outputId": "49b580e3-7ce2-4ab4-8386-c7e82af7c328"
      },
      "source": [
        "# Mostrar los n mayores y menores valores de una variable\n",
        "\n",
        "print(mtcars.nlargest(5,'hp'))\n",
        "print(iris.nsmallest(6,'Petal.Length'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                    mpg  cyl   disp   hp  drat  ...   qsec  vs  am  gear  carb\n",
            "Maserati Bora      15.0    8  301.0  335  3.54  ...  14.60   0   1     5     8\n",
            "Ford Pantera L     15.8    8  351.0  264  4.22  ...  14.50   0   1     5     4\n",
            "Duster 360         14.3    8  360.0  245  3.21  ...  15.84   0   0     3     4\n",
            "Camaro Z28         13.3    8  350.0  245  3.73  ...  15.41   0   0     3     4\n",
            "Chrysler Imperial  14.7    8  440.0  230  3.23  ...  17.42   0   0     3     4\n",
            "\n",
            "[5 rows x 11 columns]\n",
            "    Sepal.Length  Sepal.Width  Petal.Length  Petal.Width Species\n",
            "23           4.6          3.6           1.0          0.2  setosa\n",
            "14           4.3          3.0           1.1          0.1  setosa\n",
            "15           5.8          4.0           1.2          0.2  setosa\n",
            "36           5.0          3.2           1.2          0.2  setosa\n",
            "3            4.7          3.2           1.3          0.2  setosa\n",
            "17           5.4          3.9           1.3          0.4  setosa\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "da86VF6x3YWv"
      },
      "source": [
        "## Modificacion de DataFrames\n",
        "Aca se van a mostrar diferentes maneras de modificar los dataframes"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Renombrar Columnas"
      ],
      "metadata": {
        "id": "1o0vYN9oyqSA"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pEGErJb83knW",
        "outputId": "de29ac1e-10e3-4b81-fc28-f5eef28d683b"
      },
      "source": [
        "# Renombrar columnas\n",
        "\n",
        "iris1=iris.copy()\n",
        "iris1.columns = ['Sepal_L',  'Sepal_W', 'Petal_L', 'Petal.W', 'Species'] # Se pueden cambiar todos los nombres de una columna\n",
        "print(iris1.head())\n",
        "\n",
        "iris1=iris1.rename(columns={'Sepal_L': 'Sepal.L', 'Sepal_W': 'Sepal.W'}) # Se pueden cambiar algunos\n",
        "print(iris1.head())\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Sepal_L  Sepal_W  Petal_L  Petal.W Species\n",
            "1      5.1      3.5      1.4      0.2  setosa\n",
            "2      4.9      3.0      1.4      0.2  setosa\n",
            "3      4.7      3.2      1.3      0.2  setosa\n",
            "4      4.6      3.1      1.5      0.2  setosa\n",
            "5      5.0      3.6      1.4      0.2  setosa\n",
            "   Sepal.L  Sepal.W  Petal_L  Petal.W Species\n",
            "1      5.1      3.5      1.4      0.2  setosa\n",
            "2      4.9      3.0      1.4      0.2  setosa\n",
            "3      4.7      3.2      1.3      0.2  setosa\n",
            "4      4.6      3.1      1.5      0.2  setosa\n",
            "5      5.0      3.6      1.4      0.2  setosa\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Reordenar Columnas"
      ],
      "metadata": {
        "id": "ZUoQiWb6yuGZ"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xI72hbKl-zK8",
        "outputId": "c60337d3-84fe-4784-db7e-0e24feced2da"
      },
      "source": [
        "# Reordenar columnas (stata order)\n",
        "\n",
        "iris1=iris1[['Species', 'Petal_L', 'Petal.W', 'Sepal.L',  'Sepal.W' ]]\n",
        "\n",
        "iris1 = iris1.loc[:, ['Species', 'Petal_L', 'Petal.W', 'Sepal.L',  'Sepal.W' ]] #ESto es mucho mas eficiente\n",
        "\n",
        "print(iris1.head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Species  Petal_L  Petal.W  Sepal.L  Sepal.W\n",
            "1  setosa      1.4      0.2      5.1      3.5\n",
            "2  setosa      1.4      0.2      4.9      3.0\n",
            "3  setosa      1.3      0.2      4.7      3.2\n",
            "4  setosa      1.5      0.2      4.6      3.1\n",
            "5  setosa      1.4      0.2      5.0      3.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generacion de una Variable"
      ],
      "metadata": {
        "id": "cZjS-CTXyzEQ"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QqqxDFvsHsRC",
        "outputId": "140fd87d-0188-46a4-ac74-2e86ef1a7cdf"
      },
      "source": [
        "# Generacion de una variable\n",
        "iris1['multi']=iris1['Sepal.L']*iris1['Sepal.W']\n",
        "print(iris1.head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Species  Petal_L  Petal.W  Sepal.L  Sepal.W  multi\n",
            "1  setosa      1.4      0.2      5.1      3.5  17.85\n",
            "2  setosa      1.4      0.2      4.9      3.0  14.70\n",
            "3  setosa      1.3      0.2      4.7      3.2  15.04\n",
            "4  setosa      1.5      0.2      4.6      3.1  14.26\n",
            "5  setosa      1.4      0.2      5.0      3.6  18.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cambiar los valores de una columna sujeto a condicion"
      ],
      "metadata": {
        "id": "_GsefKgyy2-g"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iHuJv3FoE8uQ",
        "outputId": "249c201a-2d5e-4e46-857a-6c6eb4195150"
      },
      "source": [
        "# cambiar los valores de una columna sujeto a condicion\n",
        "\n",
        "iris1['petalo_largo']=np.where(iris1['Sepal.L']>6,2,0) # Esta funcion es parecida a SI de excel\n",
        "print(iris1['petalo_largo'].value_counts())\n",
        "\n",
        "iris1.loc[iris1['Sepal.L']>6, 'petalo_largo'] = 1\n",
        "print(iris1['petalo_largo'].value_counts())\n",
        "\n",
        "\n",
        "iris1['tam_petalo']=np.select([ iris1['Sepal.L']<=5, (iris1['Sepal.L']>5) & (iris1['Sepal.L']<=6),\n",
        "                                 iris1['Sepal.L']>6],\n",
        "    [1,2 ,3],\n",
        "    default=0\n",
        "    ) # Se debe entregar una lista de condiciones y una lista de resultados para cada condicion\n",
        "print(iris1['tam_petalo'].value_counts())\n",
        "  # Para reemplazar con nulos\n",
        "iris1['tam_petalo']=np.where(iris1['tam_petalo']==2, None, iris1['tam_petalo'])\n",
        "print(iris1['tam_petalo'].value_counts())\n",
        "\n",
        "print(iris1.head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    89\n",
            "2    61\n",
            "Name: petalo_largo, dtype: int64\n",
            "0    89\n",
            "1    61\n",
            "Name: petalo_largo, dtype: int64\n",
            "3    61\n",
            "2    57\n",
            "1    32\n",
            "Name: tam_petalo, dtype: int64\n",
            "3    61\n",
            "1    32\n",
            "Name: tam_petalo, dtype: int64\n",
            "  Species  Petal_L  Petal.W  Sepal.L  Sepal.W  multi  petalo_largo tam_petalo\n",
            "1  setosa      1.4      0.2      5.1      3.5  17.85             0       None\n",
            "2  setosa      1.4      0.2      4.9      3.0  14.70             0          1\n",
            "3  setosa      1.3      0.2      4.7      3.2  15.04             0          1\n",
            "4  setosa      1.5      0.2      4.6      3.1  14.26             0          1\n",
            "5  setosa      1.4      0.2      5.0      3.6  18.00             0          1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Reemplazar Valores"
      ],
      "metadata": {
        "id": "G3DdpxT2J-MB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "retiros.replace(0, np.nan, inplace=True)\n",
        "\n",
        "# This differs from updating with .loc or .iloc, which require you to specify a location to update with some value.\n"
      ],
      "metadata": {
        "id": "2DhKds26KDO4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Contar y  Reemplazar valores nulos"
      ],
      "metadata": {
        "id": "Xvz8xV1szCux"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R4suKfcgIa4Q",
        "outputId": "622076ad-ce64-4ccd-f257-19ad83f40a41"
      },
      "source": [
        "# Contar nulos\n",
        "\n",
        "print(iris1.isnull().sum())\n",
        "\n",
        "# Reemplazar valores nulos\n",
        "iris1['tam_petalo']=iris1['tam_petalo'].fillna(2)\n",
        "print(iris1['tam_petalo'].value_counts())\n",
        "\n",
        "print(iris1.head())\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Species          0\n",
            "Petal_L          0\n",
            "Petal.W          0\n",
            "Sepal.L          0\n",
            "Sepal.W          0\n",
            "multi            0\n",
            "petalo_largo     0\n",
            "tam_petalo      57\n",
            "dtype: int64\n",
            "3    61\n",
            "2    57\n",
            "1    32\n",
            "Name: tam_petalo, dtype: int64\n",
            "  Species  Petal_L  Petal.W  Sepal.L  Sepal.W  multi  petalo_largo  tam_petalo\n",
            "1  setosa      1.4      0.2      5.1      3.5  17.85             0           2\n",
            "2  setosa      1.4      0.2      4.9      3.0  14.70             0           1\n",
            "3  setosa      1.3      0.2      4.7      3.2  15.04             0           1\n",
            "4  setosa      1.5      0.2      4.6      3.1  14.26             0           1\n",
            "5  setosa      1.4      0.2      5.0      3.6  18.00             0           1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mantener Eliminar filas (registros) sujeto a condicion"
      ],
      "metadata": {
        "id": "8GFvTsSCzGYJ"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DmU0DK4gJyes"
      },
      "source": [
        "# Mantener Eliminar filas sujeto a condicion\n",
        "mtcars1=mtcars.copy()\n",
        "\n",
        "mtcars1=mtcars1[mtcars1['cyl']>4]\n",
        "mtcars1=mtcars1.query('cyl==8 & hp>150')\n",
        "# Se puede usar .query(cyl.notnull())\n",
        "# para isin df.query('columna in @lista')\n",
        "\n",
        "#Comando .isin\n",
        "mtcars1=mtcars1[mtcars1['gear'].isin([4,5])]\n",
        "#Que no este en la lista (usando ~)\n",
        "mtcars1=mtcars1[~(mtcars1['gear'].isin([3]))]\n",
        "\n",
        "DF = DF[:-1] # Borra la ultima fila\n",
        "\n",
        "#Comando between\n",
        "#res_p2=res_pers(datos_presu_0[datos_presu_0['vtas_anno'].between(2000, 4000, inclusive='right')])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Eliminar columnas"
      ],
      "metadata": {
        "id": "n-llzHGXzLyR"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6JqbV7nQOgdv",
        "outputId": "37f6cf18-5185-4117-e73b-246fde695138"
      },
      "source": [
        "# Eliminar columnas\n",
        "\n",
        "iris1 =iris1.drop(['petalo_largo', 'tam_petalo'], axis=1)\n",
        "print(iris1.head())\n",
        "iris1=iris1.drop(columns=['multi'])\n",
        "print(iris1.head())\n",
        "\n",
        "#pd.pop('columna') # se queda con la columa que se indica y la elimina del df\n",
        "#cleaned_df.pop('Time')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Species  Petal_L  Petal.W  Sepal.L  Sepal.W  multi\n",
            "1  setosa      1.4      0.2      5.1      3.5  17.85\n",
            "2  setosa      1.4      0.2      4.9      3.0  14.70\n",
            "3  setosa      1.3      0.2      4.7      3.2  15.04\n",
            "4  setosa      1.5      0.2      4.6      3.1  14.26\n",
            "5  setosa      1.4      0.2      5.0      3.6  18.00\n",
            "  Species  Petal_L  Petal.W  Sepal.L  Sepal.W\n",
            "1  setosa      1.4      0.2      5.1      3.5\n",
            "2  setosa      1.4      0.2      4.9      3.0\n",
            "3  setosa      1.3      0.2      4.7      3.2\n",
            "4  setosa      1.5      0.2      4.6      3.1\n",
            "5  setosa      1.4      0.2      5.0      3.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mantener columnas"
      ],
      "metadata": {
        "id": "HefaO-qhzQqR"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ABc8atqSP_8u",
        "outputId": "7e217123-b89a-4f16-d7cc-aaa01106f5ae"
      },
      "source": [
        "# Mantener columnas (Keep)\n",
        "\n",
        "iris1=iris1[['Species', 'Petal_L', 'Petal.W']]\n",
        "print(iris1.head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Species  Petal_L  Petal.W\n",
            "1  setosa      1.4      0.2\n",
            "2  setosa      1.4      0.2\n",
            "3  setosa      1.3      0.2\n",
            "4  setosa      1.5      0.2\n",
            "5  setosa      1.4      0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ordenar por columnas"
      ],
      "metadata": {
        "id": "bXF_NhKEze5J"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h7QgXSLoUQPr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ab16990-4c5d-4466-d1d6-b89e38536496"
      },
      "source": [
        "# Ordenar por columnas (sort)\n",
        "\n",
        "\n",
        "print(mtcars.sort_values(by=['hp', 'cyl']).head())\n",
        "\n",
        "print(mtcars.sort_values(by=['hp', 'cyl'], ascending=[False, True]).head())\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                 mpg  cyl   disp  hp  drat     wt   qsec  vs  am  gear  carb\n",
            "Honda Civic     30.4    4   75.7  52  4.93  1.615  18.52   1   1     4     2\n",
            "Merc 240D       24.4    4  146.7  62  3.69  3.190  20.00   1   0     4     2\n",
            "Toyota Corolla  33.9    4   71.1  65  4.22  1.835  19.90   1   1     4     1\n",
            "Fiat 128        32.4    4   78.7  66  4.08  2.200  19.47   1   1     4     1\n",
            "Fiat X1-9       27.3    4   79.0  66  4.08  1.935  18.90   1   1     4     1\n",
            "                    mpg  cyl   disp   hp  drat  ...   qsec  vs  am  gear  carb\n",
            "Maserati Bora      15.0    8  301.0  335  3.54  ...  14.60   0   1     5     8\n",
            "Ford Pantera L     15.8    8  351.0  264  4.22  ...  14.50   0   1     5     4\n",
            "Duster 360         14.3    8  360.0  245  3.21  ...  15.84   0   0     3     4\n",
            "Camaro Z28         13.3    8  350.0  245  3.73  ...  15.41   0   0     3     4\n",
            "Chrysler Imperial  14.7    8  440.0  230  3.23  ...  17.42   0   0     3     4\n",
            "\n",
            "[5 rows x 11 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Trabajar con duplicados"
      ],
      "metadata": {
        "id": "T4teOLdf65Ng"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NfU39Xfw_Kd0"
      },
      "source": [
        "# Trabajando con los duplicados (hay que generar bases con duplicados para poder trabajar aca)\n",
        "\n",
        "# Eliminacion de duplicados Obtener valores unicos (select distinct)\n",
        "'''\n",
        "df=df.drop_duplicates()\n",
        "df=df.unique()\n",
        "'''\n",
        "\n",
        "#Eliminar duplicados en una lista\n",
        "mylist = [\"a\", \"b\", \"a\", \"c\", \"c\"]\n",
        "mylist = list(dict.fromkeys(mylist))\n",
        "print(mylist)\n",
        "\n",
        "# Mantener solo los duplicados\n",
        "\n",
        "deduc_1924[deduc_1924[['at', 'contrut']].duplicated(keep=False)]\n",
        "bd_rend['duplicado']=bd_rend['Rut'].duplicated(keep=False) # Esto crea una marca si esta duplicado\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RG6kxCWQMwhI"
      },
      "source": [
        "## Modificaciones avanzadas de DataFrames"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BngI-3uOASQm"
      },
      "source": [
        "###Agrupar por (groupby)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S-jyURKkMs6P",
        "outputId": "511a659f-ec81-47e0-a00b-6eb6cbf1b381"
      },
      "source": [
        "# Collapse\n",
        "\n",
        "print(mtcars.groupby(['cyl', 'carb'], as_index=False)[['disp', 'hp']].mean())\n",
        "\n",
        "print(mtcars.groupby(['cyl'], as_index=False)[['disp', 'hp']].agg({'disp':['min', 'max'], 'hp':'sum'}))\n",
        "\n",
        "'''\n",
        "nunique es para count distinct\n",
        "observed=True se debe usar cuando las variables son categoricas\n",
        "'''\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   cyl  carb    disp     hp\n",
            "0    4     1   91.38   77.4\n",
            "1    4     2  116.60   87.0\n",
            "2    6     1  241.50  107.5\n",
            "3    6     4  163.80  116.5\n",
            "4    6     6  145.00  175.0\n",
            "5    8     2  345.50  162.5\n",
            "6    8     3  275.80  180.0\n",
            "7    8     4  405.50  234.0\n",
            "8    8     8  301.00  335.0\n",
            "  cyl   disp           hp\n",
            "         min    max   sum\n",
            "0   4   71.1  146.7   909\n",
            "1   6  145.0  258.0   856\n",
            "2   8  275.8  472.0  2929\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rxTgFeH0AVmu"
      },
      "source": [
        "### Rerodenar (reshape)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3w82RAjkOMSG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08368958-5a4d-476b-d2d8-68f35a8d133d"
      },
      "source": [
        "# Reshape long to wide\n",
        "produc_1=data('Produc')[['state', 'year', 'gsp']]\n",
        "print(produc_1.head())\n",
        "produc_w=produc_1.pivot(index='state', columns='year', values='gsp')\n",
        "produc_w=produc_w.reset_index()\n",
        "print('\\nlong to wide')\n",
        "print(produc_w.head())\n",
        "# Reshape wide to long\n",
        "print('\\nwide to long')\n",
        "produc_w.columns=['state', 'Y1970', 'Y1971', 'Y1972', 'Y1973', 'Y1974', 'Y1975', 'Y1976', 'Y1977', 'Y1978', 'Y1979', 'Y1980', 'Y1981', 'Y1982', 'Y1983', 'Y1984', 'Y1985', 'Y1986' ]\n",
        "produc_l=pd.wide_to_long(produc_w, [\"Y\"], i=\"state\", j=\"year\")\n",
        "print(produc_l.head())\n",
        "\n",
        "# Transponer DataFrames\n",
        "print('\\ntranspuesto')\n",
        "print(produc_l.transpose())\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     state  year    gsp\n",
            "1  ALABAMA  1970  28418\n",
            "2  ALABAMA  1971  29375\n",
            "3  ALABAMA  1972  31303\n",
            "4  ALABAMA  1973  33430\n",
            "5  ALABAMA  1974  33749\n",
            "\n",
            "long to wide\n",
            "year       state    1970    1971    1972  ...    1983    1984    1985    1986\n",
            "0        ALABAMA   28418   29375   31303  ...   42245   45118   46849   48409\n",
            "1        ARIZONA   19288   21040   23289  ...   35963   40010   43350   46058\n",
            "2       ARKANSAS   15392   16177   17702  ...   24415   26512   27159   28168\n",
            "3     CALIFORNIA  263933  265600  281159  ...  390528  420525  444082  464550\n",
            "4       COLORADO   25689   27341   29624  ...   46523   49332   50820   51781\n",
            "\n",
            "[5 rows x 18 columns]\n",
            "\n",
            "wide to long\n",
            "                      Y\n",
            "state      year        \n",
            "ALABAMA    1970   28418\n",
            "ARIZONA    1970   19288\n",
            "ARKANSAS   1970   15392\n",
            "CALIFORNIA 1970  263933\n",
            "COLORADO   1970   25689\n",
            "\n",
            "transpuesto\n",
            "state ALABAMA ARIZONA ARKANSAS  ... WEST_VIRGINIA WISCONSIN WYOMING\n",
            "year     1970    1970     1970  ...          1986      1986    1986\n",
            "Y       28418   19288    15392  ...         21705     70171   10870\n",
            "\n",
            "[1 rows x 816 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aG2HTOYk9M9Y"
      },
      "source": [
        "## Union de varios DataFrames"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NNIAME1y9hEf"
      },
      "source": [
        "###Merge"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1_cteYe9TK4",
        "outputId": "d7510ac3-110d-449d-cea2-b6e4aee2da8a"
      },
      "source": [
        "# Merge dfs\n",
        "\n",
        "\n",
        "produc_1970=data('Produc')[data('Produc')['year']==1970][['state', 'gsp']]\n",
        "produc_1970.columns=['state', 'gsp_1970']\n",
        "\n",
        "produc_1986=data('Produc')[data('Produc')['year']==1986][['state', 'gsp']]\n",
        "produc_1986.columns=['state', 'gsp_1986']\n",
        "\n",
        "produc_1970_1986=produc_1970.merge(produc_1986, on=['state'], how='inner', indicator=True) # how puede ser inner, outer, left o right.  indicator =True genera una variable _merge que indica de dónde viene el dato.\n",
        "\n",
        "print(produc_1970.head())\n",
        "print(produc_1986.head())\n",
        "print(produc_1970_1986.head())\n",
        "\n",
        "\n",
        "# Merge para pandas series\n",
        "\n",
        "#res_personas=pd.merge(res_p1.rename('p1'), res_p2.rename('p2'), right_index=True, left_index=True)\n",
        "#res_personas=res_personas.merge(res_p3.rename('p3'), right_index=True, left_index=True)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         state  gsp_1970\n",
            "1      ALABAMA     28418\n",
            "18     ARIZONA     19288\n",
            "35    ARKANSAS     15392\n",
            "52  CALIFORNIA    263933\n",
            "69    COLORADO     25689\n",
            "         state  gsp_1986\n",
            "17     ALABAMA     48409\n",
            "34     ARIZONA     46058\n",
            "51    ARKANSAS     28168\n",
            "68  CALIFORNIA    464550\n",
            "85    COLORADO     51781\n",
            "        state  gsp_1970  gsp_1986 _merge\n",
            "0     ALABAMA     28418     48409   both\n",
            "1     ARIZONA     19288     46058   both\n",
            "2    ARKANSAS     15392     28168   both\n",
            "3  CALIFORNIA    263933    464550   both\n",
            "4    COLORADO     25689     51781   both\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge de 2 series\n",
        "\n",
        "res_ent=round(bd_ent.query('AT2017Total<1e9 & improd_2018==0')['AT2017Total'].describe())\n",
        "res_post=round(bd_post.query('AT2017Total<1e9 & improd_2018==0')['AT2017Total'].describe())\n",
        "\n",
        "\n",
        "res=pd.merge(res_ent, res_post, right_index = True, left_index = True)"
      ],
      "metadata": {
        "id": "Cpf4fCaKP3CF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T3nPx8Ea9jbk"
      },
      "source": [
        "###Append"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "LCsio1wx9au4",
        "outputId": "71cf1c6a-a7fe-4e05-bb1d-2398e3856b6e"
      },
      "source": [
        "# Append archivos\n",
        "\n",
        "mtcars8=mtcars[mtcars.cyl==8]\n",
        "mtcars6=mtcars[mtcars.cyl==6]\n",
        "mtcars4=mtcars[mtcars.cyl==4]\n",
        "\n",
        "\n",
        "mtcars864=pd.concat([mtcars4, mtcars6, mtcars8], ignore_index=True) # Para pegar myultiples DF\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n df_padron=df_padron.append(pad_aux, ignore_index=True)\\n\\n\\nres=res_g1.append([res_g2, res_g3], ignore_index=True) \\n\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_66vE1VUDK3"
      },
      "source": [
        "## Calculo de variables especiales"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hVqaFZClMjSH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5abafbc-abbe-4b00-dfae-49dd2465d2ae"
      },
      "source": [
        "# generacion de _n para distintos grupos\n",
        "\n",
        "mtcars1=mtcars.copy()\n",
        "\n",
        "\n",
        "mtcars1['n_acum'] = mtcars1.groupby('carb').cumcount() #Ojo que parte desde 0!!!!!\n",
        "\n",
        "print(mtcars1.sort_values(by=['carb', 'n_acum']).head(10))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                    mpg  cyl   disp   hp  drat  ...  vs  am  gear  carb  n_acum\n",
            "Datsun 710         22.8    4  108.0   93  3.85  ...   1   1     4     1       0\n",
            "Hornet 4 Drive     21.4    6  258.0  110  3.08  ...   1   0     3     1       1\n",
            "Valiant            18.1    6  225.0  105  2.76  ...   1   0     3     1       2\n",
            "Fiat 128           32.4    4   78.7   66  4.08  ...   1   1     4     1       3\n",
            "Toyota Corolla     33.9    4   71.1   65  4.22  ...   1   1     4     1       4\n",
            "Toyota Corona      21.5    4  120.1   97  3.70  ...   1   0     3     1       5\n",
            "Fiat X1-9          27.3    4   79.0   66  4.08  ...   1   1     4     1       6\n",
            "Hornet Sportabout  18.7    8  360.0  175  3.15  ...   0   0     3     2       0\n",
            "Merc 240D          24.4    4  146.7   62  3.69  ...   1   0     4     2       1\n",
            "Merc 230           22.8    4  140.8   95  3.92  ...   1   0     4     2       2\n",
            "\n",
            "[10 rows x 12 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yuZtgib73w_1",
        "outputId": "300c7fe0-659e-4937-bd0d-4cbfa2527612"
      },
      "source": [
        "# Asignacion de quantiles\n",
        "iris1=iris.copy()\n",
        "iris1['decil_sl']=pd.qcut(iris['Sepal.Length'],5, labels=False)\n",
        "iris1['percentil_sl']=iris['Sepal.Length'].rank(pct=True) # Entrega el ranking en tanto por 1\n",
        "\n",
        "from scipy import stats\n",
        "\n",
        "iris1['percentil_sl1']=[stats.percentileofscore(iris['Sepal.Length'], a, 'rank') for a in iris['Sepal.Length']]\n",
        "\n",
        "print(iris1.tail())\n",
        "print(iris1['decil_sl'].value_counts(sort=False))\n",
        "\n",
        "'''\n",
        "pasando rank a percentiles enteros\n",
        "datos_rep['decil']=np.select([datos_rep['perc2']*100<=a for a in list(range(10,110, 10))], list(range(1,11)), default=0)\n",
        "datos_rep['percentil2']=np.select([datos_rep['perc2']*100<=a for a in list(range(1,101, 1))], list(range(1,101)), default=0)\n",
        "'''\n",
        "\n",
        "#https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.percentileofscore.html\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Sepal.Length  Sepal.Width  ...  percentil_sl  percentil_sl1\n",
            "146           6.7          3.0  ...      0.843333      84.333333\n",
            "147           6.3          2.5  ...      0.693333      69.333333\n",
            "148           6.5          3.0  ...      0.786667      78.666667\n",
            "149           6.2          3.4  ...      0.650000      65.000000\n",
            "150           5.9          3.0  ...      0.546667      54.666667\n",
            "\n",
            "[5 rows x 8 columns]\n",
            "0    32\n",
            "1    33\n",
            "2    30\n",
            "3    25\n",
            "4    30\n",
            "Name: decil_sl, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EqoWNLG56bcK",
        "outputId": "6b8315b7-30b1-4e26-dfe3-dd2adc639f98"
      },
      "source": [
        "# Ranking de una variable\n",
        "iris1['rank_sl'] = iris['Sepal.Length'].rank(method='max', ascending=True)\n",
        "print(iris1.sort_values(by=['Sepal.Length']).head())\n",
        "\n",
        "# Si se quiere usar el ranking en sentido inverso, se debe usar la opcion ascending=False"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Sepal.Length  Sepal.Width  Petal.Length  ...  Species decil_sl  rank_sl\n",
            "14           4.3          3.0           1.1  ...   setosa        0      1.0\n",
            "43           4.4          3.2           1.3  ...   setosa        0      4.0\n",
            "39           4.4          3.0           1.3  ...   setosa        0      4.0\n",
            "9            4.4          2.9           1.4  ...   setosa        0      4.0\n",
            "42           4.5          2.3           1.3  ...   setosa        0      5.0\n",
            "\n",
            "[5 rows x 7 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3GcMQo8j7W9r",
        "outputId": "882cedf6-50c0-4572-b006-cf61407309eb"
      },
      "source": [
        "# Sumar, Encontrar el maximo entre dos o mas variables\n",
        "iris1['s_max']=iris1[['Sepal.Length', 'Sepal.Width']].max(axis=1)\n",
        "iris1['s_sum']=iris1[['Sepal.Length', 'Sepal.Width']].sum(axis=1)\n",
        "print(iris1.head())\n",
        "\n",
        "'''\n",
        "df['e'] = df[col_list].sum(axis=1)\n",
        "df['f']=df.iloc[:,0:2].sum(axis=1)\n",
        "df['g']=df.iloc[:,[0,1]].sum(axis=1)\n",
        "df['h']=df.iloc[:,[0,3]].sum(axis=1)\n",
        "df.sum(axis = 1, skipna = True)\n",
        "\n",
        "'''\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Sepal.Length  Sepal.Width  Petal.Length  ...  rank_sl s_max  s_sum\n",
            "1           5.1          3.5           1.4  ...     41.0   5.1    8.6\n",
            "2           4.9          3.0           1.4  ...     22.0   4.9    7.9\n",
            "3           4.7          3.2           1.3  ...     11.0   4.7    7.9\n",
            "4           4.6          3.1           1.5  ...      9.0   4.6    7.7\n",
            "5           5.0          3.6           1.4  ...     32.0   5.0    8.6\n",
            "\n",
            "[5 rows x 9 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xL77jy9n8wPy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efa33768-345e-42cc-e76f-1b46f2bcaca8"
      },
      "source": [
        "# Medias y sumas moviles\n",
        "\n",
        "prod_california=data('Produc')[data('Produc')['state']=='CALIFORNIA'][['state', 'year', 'gsp']]\n",
        "\n",
        "prod_california['gsp_mm3']=prod_california['gsp'].rolling(window=3).mean() # Media movil\n",
        "prod_california['gsp_sm5']=prod_california['gsp'].rolling(window=5).sum() # Suma movil\n",
        "\n",
        "print(prod_california.head(10))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         state  year     gsp        gsp_mm3    gsp_sm5\n",
            "52  CALIFORNIA  1970  263933            NaN        NaN\n",
            "53  CALIFORNIA  1971  265600            NaN        NaN\n",
            "54  CALIFORNIA  1972  281159  270230.666667        NaN\n",
            "55  CALIFORNIA  1973  293735  280164.666667        NaN\n",
            "56  CALIFORNIA  1974  298408  291100.666667  1402835.0\n",
            "57  CALIFORNIA  1975  304518  298887.000000  1443420.0\n",
            "58  CALIFORNIA  1976  320160  307695.333333  1497980.0\n",
            "59  CALIFORNIA  1977  338040  320906.000000  1554861.0\n",
            "60  CALIFORNIA  1978  359603  339267.666667  1620729.0\n",
            "61  CALIFORNIA  1979  374928  357523.666667  1697249.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Usar valores de columnas rezagados y posterior\n",
        "\n",
        "prod_california['gsp+1']=prod_california['gsp'].shift(1)\n",
        "prod_california['gsp-1']=prod_california['gsp'].shift(-1)\n",
        "print(prod_california.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nT1Aqe4Me6TZ",
        "outputId": "293a532b-73d8-45aa-b91f-89f86db3e1ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         state  year     gsp        gsp_mm3    gsp_sm5     gsp+1     gsp-1\n",
            "52  CALIFORNIA  1970  263933            NaN        NaN       NaN  265600.0\n",
            "53  CALIFORNIA  1971  265600            NaN        NaN  263933.0  281159.0\n",
            "54  CALIFORNIA  1972  281159  270230.666667        NaN  265600.0  293735.0\n",
            "55  CALIFORNIA  1973  293735  280164.666667        NaN  281159.0  298408.0\n",
            "56  CALIFORNIA  1974  298408  291100.666667  1402835.0  293735.0  304518.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sumar una variables por otra y colocarla como una variable nueva\n",
        "\n",
        "ppm_mes=ppm_mes.merge(ppm_mes.groupby('anno', as_index=False)['monto'].sum(), on='anno') # Manera engorrosa\n",
        "\n",
        "ppm_mes['monto_tot']=ppm_mes['monto'].groupby(ppm_mes['anno']).transform('sum')\n",
        "\n",
        "\n",
        "\n",
        "# Aca mas info de transform https://towardsdatascience.com/when-to-use-pandas-transform-function-df8861aa0dcf"
      ],
      "metadata": {
        "id": "Uq8Noat1gmKP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Generar dummies\n",
        "\n",
        "bd_2011=bd_2011.merge(pd.get_dummies(bd_2011['rubro_2010'], prefix='rubro'), left_index=True, right_index=True)\n"
      ],
      "metadata": {
        "id": "r5_QxE69mQtb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VaFe0E388_WM"
      },
      "source": [
        "## Trabajar con variables de Texto"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "movies=data('movies')\n",
        "\n",
        "# cambiar variable a string\n",
        "\n",
        "movies.year = movies.year.astype(str)\n",
        "\n",
        "# cambiar variable a entero\n",
        "\n",
        "movies.year = movies.year.astype('int64')\n",
        "\n",
        "# Split una variable\n",
        "movies1=movies[['title', 'year']]\n",
        "\n",
        "movies1 =movies1.merge(movies1.title.str.split(pat=' ',n=3, expand=True), left_index=True, right_index=True)\n",
        "movies1=movies1.rename(columns={0:'t1', 1:'t2', 2:'t3', 3: 't4'})\n",
        "print(movies1.head())\n",
        "\n",
        "# Buscar los casos que en una variable tienen un string\n",
        "\n",
        "movies['horror']=movies['title'].str.contains('horror', case=False) # case es case sensitive\n",
        "print('peliculas que contienen la palabra \"horror\"')\n",
        "print(movies['horror'].value_counts())\n",
        "\n",
        "movies2=movies[['title', 'year']]\n",
        "# Reemplazar un string\n",
        "\n",
        "movies2['title1']=movies2['title'].str.replace('Day', 'Dia')\n",
        "print(movies2.head())\n",
        "\n",
        "# obtener un pedazo de string\n",
        "movies2['subtitle']=movies2['title'].str.slice(start=1, stop=-3)\n",
        "print(movies2.head())\n",
        "\n",
        "\n",
        "# Encontran donde empieza un string\n",
        "\n",
        "DF_result['pru']=DF_result['nombre'].str.find('_alum', start=0)\n",
        "\n",
        "# Para dividir una columna de texto\n",
        "\n",
        "DF_result[['id1', 'id']]=DF_result['id0'].str.split('_', expand=True)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cc8jcveDZvpk",
        "outputId": "5e5d2cb3-30b1-4c11-8608-4021e2e7b121"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                      title  year       t1      t2         t3            t4\n",
            "1                         $  1971        $    None       None          None\n",
            "2         $1000 a Touchdown  1939    $1000       a  Touchdown          None\n",
            "3    $21 a Day Once a Month  1941      $21       a        Day  Once a Month\n",
            "4                   $40,000  1996  $40,000    None       None          None\n",
            "5  $50,000 Climax Show, The  1975  $50,000  Climax      Show,           The\n",
            "peliculas que contienen la palabra \"horror\"\n",
            "False    58747\n",
            "True        41\n",
            "Name: horror, dtype: int64\n",
            "                      title  year                    title1\n",
            "1                         $  1971                         $\n",
            "2         $1000 a Touchdown  1939         $1000 a Touchdown\n",
            "3    $21 a Day Once a Month  1941    $21 a Dia Once a Month\n",
            "4                   $40,000  1996                   $40,000\n",
            "5  $50,000 Climax Show, The  1975  $50,000 Climax Show, The\n",
            "                      title  ...              subtitle\n",
            "1                         $  ...                      \n",
            "2         $1000 a Touchdown  ...         1000 a Touchd\n",
            "3    $21 a Day Once a Month  ...    21 a Day Once a Mo\n",
            "4                   $40,000  ...                   40,\n",
            "5  $50,000 Climax Show, The  ...  50,000 Climax Show, \n",
            "\n",
            "[5 rows x 4 columns]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:27: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Trabajar con variables de fecha"
      ],
      "metadata": {
        "id": "QToKUVwXCFFX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear variable de fecha\n",
        "fallecidos['fecha']=pd.to_datetime(fallecidos['fecha'], format='%Y-%m-%d') # La variable a transformar debe ser de texto\n",
        "# Condiciones usando fechas\n",
        "fallecidos_tot=fallecidos_tot[fallecidos_tot['fecha']>='2020-08-01']\n"
      ],
      "metadata": {
        "id": "2HKP80G7CEkP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "'''\n",
        "Falta hacer\n",
        "\n",
        "# Cambiar string a date\n",
        "\n",
        "dfl2_fecins_limp['fecha_insc']=pd.to_datetime(dfl2_fecins_limp['FEC_INS'], format='%d/%m/%Y', errors='coerce')\n",
        "'''\n",
        "\n",
        "\n",
        "'''\n",
        "# Identificar feriados\n",
        "\n",
        "from datetime import dateimport holidaysh_cl=holidays.CL()\n",
        "\n",
        "date(2022, 6, 27) in h_cl\n",
        "\n",
        "\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "y1iItdpAlPiA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Trabajar con chunks\n",
        "\n",
        "\n",
        "Los archivos csv se pueden trabajar en chunks para poder trabajar en el isco y no en la memoria\n"
      ],
      "metadata": {
        "id": "DrcGIqLyLwzd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Primero se debe definir el tamaño de cada chunk (las filas que tiene)\n",
        "chunksize = 100000  # Define el tamaño de los chunks\n",
        "\n",
        "# Merge con chunks en disco\n",
        "\n",
        "es_primer_chunk = True\n",
        "with pd.read_csv('archivo_grande.csv', chunksize=chunksize) as reader:\n",
        "    for chunk in reader:\n",
        "        merged_chunk = pd.merge(chunk, df2, on='columna_clave')\n",
        "        merged_chunk.to_csv('archivo_merged.csv', mode='a', header=es_primer_chunk, index=False)\n",
        "        es_primer_chunk = False\n",
        "\n",
        "#Groupby con chunks en memoria\n",
        "\n",
        "# Crear un DataFrame vacío para acumular los resultados\n",
        "resultados = pd.DataFrame()\n",
        "\n",
        "# Leer el archivo CSV en chunks\n",
        "for chunk in pd.read_csv('archivo_grande.csv', chunksize=chunksize):\n",
        "    # Aplicar groupby en cada chunk\n",
        "    chunk_grouped = chunk.groupby('columna_clave')['columna_valor'].sum().reset_index()\n",
        "\n",
        "    # Acumular resultados\n",
        "    if resultados.empty:\n",
        "        resultados = chunk_grouped\n",
        "    else:\n",
        "        # Combinar resultados de los chunks\n",
        "        resultados = pd.concat([resultados, chunk_grouped], ignore_index=True)\n",
        "\n",
        "# Ahora se realiza un groupby final para sumar los valores que correspondan a la misma clave\n",
        "resultados_finales = resultados.groupby('columna_clave')['columna_valor'].sum().reset_index()\n",
        "\n"
      ],
      "metadata": {
        "id": "3qOpuXEUMA1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Manejo de listas"
      ],
      "metadata": {
        "id": "gXMLxVkzwykY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#https://note.nkmk.me/en/python-list-clear-pop-remove-del/\n",
        "#https://note.nkmk.me/en/python-list-select-replace/\n",
        "# https://note.nkmk.me/en/python-list-comprehension/\n",
        "\n",
        "\n",
        "# len(x) cuenta los elmentos de una lista x\n",
        "\n",
        "# Funciones sobre strings\n",
        "\n",
        "# s.count(x) cuenta las apariciones de x en s\n",
        "# s.find(x) retorna la posicion de x en s\n",
        "# s.replace(x,y) reemplaza x por y en el string s\n",
        "# s.upper() transforma todos los carateres del string a mayuscula\n",
        "# s.lower() transforma todos los carateres del string a minuscula\n",
        "# s.strip() remueve los espacios y otros similares al comienzo y final del string\n",
        "# s.split(\",\") divide el string s por , y convierte los elementos en una lista\n",
        "\n",
        "# s.endswith('e')\n",
        "\n",
        "#Funciones generales\n",
        "# l[i:j] entrega los elementos entre i y j-1 de la lista l\n",
        "# l.append(x) agrega el elemento x a la lista l\n",
        "# l.remove(x) elimina el primer elemento x de la lista l\n",
        "# l.pop(x) elimina el elemento en la posicion x de la lista l y mantener ese valor (y=l.pop(x))- pop() elimina el ultimo elemento\n",
        "# l.clear() elimina todos los elementos de la lista l\n",
        "# con del l[i:j] se puede eliminar slices. l[:] es equivalente a l.clear()\n",
        "# l.extend(m) Agrega los elementos de la lista m al final de la lista l. Equivalente a [1,2]+[3,4]\n",
        "# l.count(x) cuenta la veces que aparece el elmento x en l\n",
        "# l.index(x) Retorna el índice de la primera vez que el  elemento x se encuentra dentro de l. Sino se  encuentra, genera un error\n",
        "# l.sot() ordena los elementos de l\n",
        "\n",
        "# Iterar ebn lista\n",
        "# for i in lista:  Itera sobre los elementos en lista\n",
        "\n",
        "# list comprehension\n",
        "# [expression for variable_name in iterable if condition]\n",
        "# l = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
        "# evens = [i for i in l if i % 2 == 0]\n",
        "#[(X if condition else Y) for variable_name in original_list]\n",
        "# l_sub = [i2 - i1 for i1, i2 in zip(l_int1, l_int2)] Con zip se puede hacer operaciones con multiples listas\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z4tk2me3w2Ho",
        "outputId": "62486cd5-0313-4929-822d-8d1e3a8947b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 2, 3, 4]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def suma(x):\n",
        "  l = len(x)\n",
        "  if l == 0:\n",
        "    return 0\n",
        "  else:\n",
        "    last = x.pop()\n",
        "    print(last, x)\n",
        "    return suma(x) + last\n",
        "\n",
        "r=suma([1,2,3,4,5])\n",
        "print(r)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cq4dO692sDo4",
        "outputId": "6e954f30-7e0e-4cd3-af33-263a66f89fc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5 [1, 2, 3, 4]\n",
            "4 [1, 2, 3]\n",
            "3 [1, 2]\n",
            "2 [1]\n",
            "1 []\n",
            "15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Herramientas Python"
      ],
      "metadata": {
        "id": "rWmJig5nzSft"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Esto finaliza la ejecucion del algoritmo\n",
        "sys.exit(\"se finaliza el programa\")"
      ],
      "metadata": {
        "id": "emaNyKDZzNYB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tGq6wgQSdxgI"
      },
      "source": [
        "Esto es lo que tenia en un archivo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oPWnOE63JKsj",
        "outputId": "edc4ccd9-3ca7-41eb-dfa4-a9d23f207f0f"
      },
      "source": [
        "# Objetos de python\n",
        "\n",
        "largo=5\n",
        "# Crear vector de 0s\n",
        "np.zeros(largo)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ejemplos=data()\n",
        "\n",
        "print(list(ejemplos.title))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eOaMDZyZNrQD",
        "outputId": "11ec67be-dc87-442a-c2f9-70761edfc939"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Monthly Airline Passenger Numbers 1949-1960', 'Sales Data with Leading Indicator', 'Biochemical Oxygen Demand', 'Determination of Formaldehyde', 'Hair and Eye Color of Statistics Students', 'Effectiveness of Insect Sprays', 'Quarterly Earnings per Johnson & Johnson Share', 'Level of Lake Huron 1875-1972', 'Intercountry Life-Cycle Savings Data', 'Flow of the River Nile', 'Potency of Orchard Sprays', 'Results from an Experiment on Plant Growth', 'Reaction Velocity of an Enzymatic Reaction', 'Survival of passengers on the Titanic', 'The Effect of Vitamin C on Tooth Growth in Guinea Pigs', 'Student Admissions at UC Berkeley', 'Road Casualties in Great Britain 1969-84', 'UK Quarterly Gas Consumption', 'Accidental Deaths in the US 1973-1978', 'Violent Crime Rates by US State', \"Lawyers' Ratings of State Judges in the US Superior Court\", 'Personal Expenditure Data', 'Death Rates in Virginia (1940)', 'Internet Usage per Minute', \"The World's Telephones\", 'Passenger Miles on Commercial US Airlines, 1937-1960', 'New York Air Quality Measurements', \"Anscombe's Quartet of 'Identical' Simple Linear Regressions\", 'The Joyner-Boore Attenuation Data', 'The Chatterjee-Price Attitude Data', 'Quarterly Time Series of the Number of Australian Residents', 'Speed and Stopping Distances of Cars', 'Chicken Weights by Feed Type', 'Mauna Loa Atmospheric CO2 Concentration', \"Student's 3000 Criminals Data\", 'Yearly Numbers of Important Discoveries', 'Smoking, Alcohol and (O)esophageal Cancer', 'Conversion Rates of Euro Currencies', 'Old Faithful Geyser Data', \"Freeny's Revenue Data\", 'Infertility after Spontaneous and Induced Abortion', \"Edgar Anderson's Iris Data\", \"Areas of the World's Major Landmasses\", 'Luteinizing Hormone in Blood Samples', \"Longley's Economic Regression Data\", 'Annual Canadian Lynx trappings 1821-1934', 'Michelson Speed of Light Data', 'Motor Trend Car Road Tests', 'Average Yearly Temperatures in New Haven', 'Average Monthly Temperatures at Nottingham, 1920-1939', 'Classical N, P, K Factorial Experiment', 'Occupational Status of Fathers and their Sons', 'Annual Precipitation in US Cities', 'Quarterly Approval Ratings of US Presidents', 'Vapor Pressure of Mercury as a Function of Temperature', 'Locations of Earthquakes off Fiji', 'Random Numbers from Congruential Generator RANDU', 'Lengths of Major North American Rivers', 'Measurements on Petroleum Rock Samples', \"Student's Sleep Data\", \"Brownlee's Stack Loss Plant Data\", 'Monthly Sunspot Data, from 1749 to \"Present\"', 'Yearly Sunspot Data, 1700-1988', 'Monthly Sunspot Numbers, 1749-1983', 'Swiss Fertility and Socioeconomic Indicators (1888) Data', 'Yearly Treering Data, -6000-1979', 'Girth, Height and Volume for Black Cherry Trees', 'Populations Recorded by the US Census', \"Topographic Information on Auckland's Maunga Whau Volcano\", 'The Number of Breaks in Yarn during Weaving', 'Average Heights and Weights for American Women', 'Monthly Excess Returns', 'Delay in AIDS Reporting in England and Wales', 'Failures of Air-conditioning Equipment', 'Failures of Air-conditioning Equipment', 'Car Speeding and Warning Signs', 'Remission Times for Acute Myelogenous Leukaemia', 'Population of U.S. Cities', 'Spatial Location of Bramble Canes', 'Smoking Deaths Among Doctors', 'Calcium Uptake Data', 'Sugar-cane Disease Data', 'Simulated Manufacturing Process Data', 'Weight Data for Domestic Cats', 'Position of Muscle Caveolae', 'CD4 Counts for HIV-Positive Patients', 'Channing House Data', 'Population of U.S. Cities', 'Genetic Links to Left-handedness', 'Number of Flaws in Cloth', 'Carbon Monoxide Transfer', 'Dates of Coal Mining Disasters', \"Darwin's Plant Height Differences\", 'Cardiac Data for Domestic Dogs', \"Incidence of Down's Syndrome in British Columbia\", 'Behavioral and Plumage Characteristics of Hybrid Ducks', 'Counts of Balsam-fir Seedlings', 'Head Dimensions in Brothers', 'Acceleration Due to Gravity', 'Acceleration Due to Gravity', 'Failure Time of PET Film', 'Jura Quartzite Azimuths on Islay', 'Average Heights of the Rio Negro river at Manaus', 'Survival from Malignant Melanoma', 'Data from a Simulated Motorcycle Accident', 'Neurophysiological Point Process Data', 'Toxicity of Nitrofen in Aquatic Systems', 'Nodal Involvement in Prostate Cancer', 'Nuclear Power Station Construction Data', 'Neurotransmission in Guinea Pig Brains', 'Animal Survival Times', 'Pole Positions of New Caledonian Laterites', 'Cancer Remission and Cell Activity', 'Water Salinity and River Discharge', 'Survival of Rats after Radiation Doses', 'Tau Particle Decay Modes', 'Tuna Sighting Data', 'Urine Analysis Data', 'Australian Relative Wool Prices', 'data from Section 1.19', 'data from Section 1.9', 'data from Exercise 13.1, p418', 'data from Exercise 4.7, p122', 'data from Exercise 5.8, p147', 'data from Section 1.18', 'data from Section 1.14', 'data from Section 1.3', 'data from Exercise 7.7, p223', 'data from Section 1.5', 'data from Section 1.6', 'data from Section 1.16', 'data from Section 1.2', 'data from Exercise 7.6, p222', 'data from Section 1.10', 'data from Section 1.4', 'Data on 38 individuals using a kidney dialysis machine', 'data from Section 1.7', 'data from Section 1.8', 'data from Exercise 4.4, p120', 'data from Section 1.13', 'data from Section 1.15', 'data from Exercise 7.13, p225', 'data from Section 1.12', 'data from Exercise 5.6, p146', 'data from Section 1.11', 'data from Exercise 7.14, p225', 'Brain and Body Weights for 65 Species of Land Animals', \"Crohn's Disease Adverse Events Data\", 'NOx Air Pollution Data', \"Siegel's Exact Fit Example Data\", 'Aircraft Data', 'Air Quality Data', 'Alcohol Solubility in Water Data', 'Daily Means of NOx (mono-nitrogen oxides) in air', 'Campbell Bushfire Data', 'Insect Damages on Carrots', 'Cloud point of a Liquid', 'Coleman Data Set', 'Condroz Data', 'Cushny and Peebles Prolongation of Sleep Data', 'Delivery Time Data', 'Education Expenditure Data', 'Epilepsy Attacks Data Set', 'Example Data of Antille and May - for Simple Regression', 'Food Stamp Program Participation', \"Hawkins, Bradu, Kass's Artificial Data\", 'Heart Catherization Data', 'Waterflow Measurements of Kootenay River in Libby and Newgate', 'Lactic Acid Concentration Measurement Data', \"Daudin's Milk Composition Data\", 'Pension Funds Data', 'Phosphorus Content Data', 'Pilot-Plant Data', 'Possum Diversity Data', 'Pulp Fiber and Paper Data', 'Satellite Radar Image Data from near Munich', 'Salinity Data', 'Hertzsprung-Russell Diagram Data of Star Cluster CYG OB1', 'Number of International Calls from Belgium', 'Toxicity of Carboxylic Acids Data', 'Vaso Constriction Skin Data Set', \"Wagner's Hannover Employment Growth Data\", 'Modified Data on Wood Specific Gravity', 'American Math Society Survey Data', 'Experimenter Expectations', 'Moral Integration of American Cities', 'U. S. State Public-School Expenditures', 'Methods of Teaching Reading Comprehension', \"Canadian Women's Labour-Force Participation\", 'Exercise Histories of Eating-Disordered and Control Subjects', 'Fraudulent Data on IQs of Twins Raised Apart', 'Canadian Population Data', 'Voting Intentions in the 1988 Chilean Plebiscite', 'The 1907 Romanian Peasant Rebellion', \"Cowles and Davis's Data on Volunteering\", 'Self-Reports of Height and Weight', \"Davis's Data on Drive for Thinness\", 'Minnesota Wolf Depredation Data', \"Duncan's Occupational Prestige Data\", 'The 1980 U.S. Census Undercount', 'Florida County Voting', 'Crowding and Crime in U. S. Metropolitan Areas', 'Format Effects on Recall', 'Data on Depression', 'Refugee Appeals', 'Anonymity and Cooperation', 'Canadian Crime-Rates Time Series', 'Highway Accidents', 'Data on Infant-Mortality', 'Contrived Collinear Data', 'Canadian Interprovincial Migration Data', 'Status, Authoritarianism, and Conformity', \"U.S. Women's Labor-Force Participation\", \"O'Brien and Kaiser's Repeated-Measures Data\", 'Interlocking Directorates Among Major Canadian Firms', 'Chemical Composition of Pottery', 'Prestige of Canadian Occupations', 'Four Regression Datasets', 'Fertility and Contraception', 'Survey of Labour and Income Dynamics', 'Agricultural Production in Mazulu Village', 'Salaries for Professors', 'Soil Compositions of Physical and Chemical Characteristics', 'Education and Related Statistics for the U.S. States', 'Transaction data', 'GDP and Infant Mortality', 'Population of the United States', 'Vocabulary and Education', 'Weight Loss Data', \"Canadian Women's Labour-Force Participation\", 'Wool data', 'European Union Agricultural Workforces', 'Attributes of Animals', 'Subset of C-horizon of Kola Data', 'Flower Characteristics', 'Plant Species Traits Data', 'Isotopic Composition Plutonium Batches', 'Ruspini Data', 'Votes for Republican Candidate in Presidential Elections', 'Bivariate Data Set with 3 Clusters', 'affairs', 'azcabgptca', 'azdrg112', 'azpro', 'azprocedure', 'badhealth', 'fasttrakg', 'fishing', 'lbw', 'lbwgrp', 'loomis', 'mdvis', 'medpar', 'nuts', 'rwm', 'rwm1984', 'rwm5yr', 'ships', 'smoking', 'titanic', 'titanicgrp', 'Ship Accidents', 'Cost for U.S. Airlines', 'Air Quality for Californian Metropolitan Areas', 'Unemployement of Blue Collar Workers', 'Bids Received By U.S. Firms', 'Budget Share of Food for Spanish Households', 'Budget Shares for Italian Households', 'Budget Shares of British Households', 'Wages in Belgium', 'Earnings from the Current Population Survey', 'Growth of CRAN', 'Stock Market Data', 'Stated Preferences for Car Choice', 'The California Test Score Data Set', 'Choice of Brand for Catsup', 'Cigarette Consumption', 'The Cigarette Consumption Panel Data Set', \"Sales Data of Men's Fashion Stores\", 'Prices of Personal Computers', 'Choice of Brand for Crakers', 'Crime in North Carolina', 'DM Dollar Exchange Rate', \"Pricing the C's of Diamond Stones\", 'Number of Doctor Visits', 'Doctor Visits in Australia', 'Contacts With Medical Doctor', 'Earnings for Three Age Groups', 'Cost Function for Electricity Producers', 'Extramarital Affairs Data', 'Drunk Driving Laws and Traffic Deaths', 'Choice of Fishing Mode', 'Exchange Rates of US Dollar Against Other Currencies', 'Data from the Television Game Show Friend Or Foe ?', 'Daily Observations on Exchange Rates of the US Dollar Against Other Currencies', 'Gasoline Consumption', 'Wage Datas', 'Grunfeld Investment Data', 'Heating and Cooling System Choice in Newly Built Houses in California', 'Health Insurance and Hours Worked By Wives', 'The Boston HDMA Data Set', 'Heating System Choice in California Houses', 'Hedonic Prices of Cencus Tracts in Boston', 'Sales Prices of Houses in the City of Windsor', 'Ice Cream Consumption', 'Economic Journals Dat Set', 'Willingness to Pay for the Preservation of the Kakadu National Park', 'Choice of Brand for Ketchup', \"Klein's Model I\", 'Wages and Hours Worked', 'Belgian Firms', 'The Massashusets Test Score Data Set', 'Wages and Education of Young Males', 'Level of Calculus Attained for Students Taking Advanced Micro-economics', 'Structure of Demand for Medical Care', 'Production for SIC 33', 'Mode Choice', 'Data to Study Travel Mode Choice', \"International Expansion of U.S. Mofa's (majority-owned Foreign Affiliates in Fire (finance, Insurance and Real Estate)\", 'Labor Supply Data', 'Municipal Expenditure Data', 'Willingness to Pay for the Preservation of the Alentejo Natural Park', 'Cost Function for Electricity Producers, 1955', 'Visits to Physician Office', 'Oil Investment', 'Panel Survey of Income Dynamics', 'Labor Force Participation', 'Dynamic Relation Between Patents and R&D', 'Patents, R&D and Technological Spillovers for a Panel of Firms', 'Pound-dollar Exchange Rate', 'Us States Production', 'Return to Schooling', \"Returns on Standard & Poor's 500 Index\", 'Wages and Schooling', 'Visits to Lake Somerville', 'Effects on Learning of Small Class Sizes', 'Strike Duration Data', 'Strikes Duration', 'Number of Strikes in Us Manufacturing', 'The Penn Table', 'Households Tobacco Budget Share', 'Stated Preferences for Train Traveling', 'Statewide Data on Transportation Equipment Manufacturing', 'Evaluating Treatment Effect of Training on Earnings', 'Choice of Brand for Tuna', 'US Finance Industry Profits', 'Official Secrecy of the United States Government', 'Standard abbreviations for states of the United States', 'Number of Words in US Tax Law', 'Unemployment Duration', 'Unemployment Duration', 'Provision of University Teaching and Research', 'Medical Expenses in Viet-nam (household Level)', 'Medical Expenses in Viet-nam (individual Level)', 'Panel Datas of Individual Wages', 'Wages, Experience and Schooling', 'Wife Working Hours', 'Yen-dollar Exchange Rate', 'Choice of Brand for Yogurts', 'Countries in Banking Crises', 'Income Inequality in the US', 'Names with Character Set Problems', 'Political knowledge in the US and Europe', \"A study of Parkinson's disease and APOE, LRRK2, SNCA makers\", 'ALDH2 markers and Alcoholism', \"APOE/APOC1 markers and Alzheimer's\", 'Cystic fibrosis data', \"Crohn's disease data\", 'Friedreich Ataxia data', 'A case-control data involving four SNPs with missing genotype', 'The HLA data', 'An example data for Manhattan plot with annotation', 'An example pedigree data', 'An example pedigree', \"A study of Parkinson's disease and MAO gene\", 'Example data for ACEnucfam', 'An example data for Manhattan plot', \"A study of Alzheimer's disease with eight SNPs and APOE\", 'Prices of 50,000 round cut diamonds', 'US economic time series.', 'Midwest demographics.', 'Movie information and user ratings from IMDB.com.', 'Fuel economy data from 1999 and 2008 for 38 popular models of car', 'An updated and expanded version of the mammals sleep dataset.', 'Terms of 10 presidents from Eisenhower to Bush W.', 'Vector field of seal movements.', \"Arbuthnot's data on male and female birth ratios in London from 1629-1710.\", \"Bowley's data on values of British and Irish trade, 1855-1899\", \"Cavendish's Determinations of the Density of the Earth\", 'Chest measurements of 5738 Scottish Militiamen', 'Cushny-Peebles Data: Soporific Effects of Scopolamine Derivatives', 'Cushny-Peebles Data: Soporific Effects of Scopolamine Derivatives', \"Edgeworth's counts of dactyls in Virgil's Aeneid\", \"Elderton and Pearson's (1910) data on drinking and wages\", \"Waite's data on Patterns in Fingerprints\", \"Galton's data on the heights of parents and their children\", \"Galton's data on the heights of parents and their children, by child\", 'Data from A.-M. Guerry, \"Essay on the Moral Statistics of France\"', \"W. Stanley Jevons' data on numerical discrimination\", \"van Langren's Data on Longitude Distance between Toledo and Rome\", \"van Langren's Data on Longitude Distance between Toledo and Rome\", \"Macdonell's Data on Height and Finger Length of Criminals, used by Gosset (1908)\", \"Macdonell's Data on Height and Finger Length of Criminals, used by Gosset (1908)\", \"Michelson's Determinations of the Velocity of Light\", \"Michelson's Determinations of the Velocity of Light\", \"Data from Minard's famous graphic map of Napoleon's march on Moscow\", \"Data from Minard's famous graphic map of Napoleon's march on Moscow\", \"Data from Minard's famous graphic map of Napoleon's march on Moscow\", \"Florence Nightingale's data on deaths from various causes in the Crimean War\", 'Latitudes and Longitudes of 39 Points in 11 Old Maps', \"Pearson and Lee's data on the heights of parents and children classified by gender\", 'Polio Field Trials Data', \"Parent-Duchatelet's time-series data on the number of prostitutes in Paris\", 'Trial of the Pyx', 'Statistics of Deadly Quarrels', \"John Snow's map and data on the 1854 London Cholera outbreak\", \"John Snow's map and data on the 1854 London Cholera outbreak\", \"John Snow's map and data on the 1854 London Cholera outbreak\", \"John Snow's map and data on the 1854 London Cholera outbreak\", \"Playfair's Data on Wages and the Price of Wheat\", \"Playfair's Data on Wages and the Price of Wheat\", \"Student's (1906) Yeast Cell Counts\", \"Student's (1906) Yeast Cell Counts\", \"Darwin's Heights of Cross- and Self-fertilized Zea May Pairs\", 'Yield data from a Minnesota barley trial', 'Atmospheric environmental conditions in New York City', 'Engine exhaust fumes from burning ethanol', 'Melanoma skin cancer incidence', 'Heights of New York Choral Society singers', 'Australian AIDS Survival Data', 'Brain and Body Weights for 28 Species', 'Housing Values in Suburbs of Boston', 'Data from 93 Cars on Sale in the USA in 1993', \"Diagnostic Tests on Patients with Cushing's Syndrome\", 'DDT in Kale', 'Level of GAG in Urine of Children', 'Numbers of Car Insurance claims', 'Survival from Malignant Melanoma', 'Tests of Auditory Perception in Children with OME', 'Diabetes in Pima Indian Women', 'Diabetes in Pima Indian Women', 'Diabetes in Pima Indian Women', 'Blood Pressure in Rabbits', 'Accelerated Testing of Tyre Rubber', 'Returns of the Standard and Poors 500', 'Growth Curves for Sitka Spruce Trees in 1988', 'Growth Curves for Sitka Spruce Trees in 1989', 'AFM Compositions of Aphyric Skye Lavas', 'Effect of Swedish Speed Limits on Accidents', 'Nutritional and Marketing Information on US Cereals', 'The Effect of Punishment Regimes on Crime Rates', \"Veteran's Administration Lung Cancer Trial\", 'Determinations of Nickel Content', 'Accidental Deaths in the US 1973-1978', 'Anorexia Data on Weight Change', 'Presence of Bacteria after Drug Treatments', 'Body Temperature Series of Beaver 1', 'Body Temperature Series of Beaver 2', 'Biopsy Data on Breast Cancer Patients', 'Risk Factors Associated with Low Infant Birth Weight', 'Data from a cabbage field trial', 'Colours of Eyes and Hair of People in Caithness', 'Anatomical Data from Domestic Cats', 'Heat Evolved by Setting Cements', 'Copper in Wholemeal Flour', 'Co-operative Trial in Analytical Chemistry', 'Performance of Computer CPUs', 'Morphological Measurements on Leptograpsus Crabs', 'Monthly Deaths from Lung Diseases in the UK', 'Deaths of Car Drivers in Great Britain 1969-84', 'Foraging Ecology of Bald Eagles', 'Seizure Counts for Epileptics', 'Ecological Factors in Farm Management', 'Measurements of Forensic Glass Fragments', \"Forbes' Data on Boiling Points in the Alps\", 'Velocities for 82 Galaxies', 'Remission Times of Leukaemia Patients', 'Rat Genotype Data', 'Old Faithful Geyser Data', 'Line Transect of Soil in Gilgai Territory', 'Record Times in Scottish Hill Races', 'Frequency Table from a Copenhagen Housing Conditions Survey', 'Yields from a Barley Field Trial', 'Survival Times and White Blood Counts for Leukaemia Patients', 'Brain and Body Weights for 62 Species of Land Mammals', 'Data from a Simulated Motorcycle Accident', 'Age of Menarche in Warsaw', \"Michelson's Speed of Light Data\", 'Minnesota High School Graduates of 1938', 'Accelerated Life Testing of Motorettes', 'Effect of Calcium Chloride on Muscle Contraction in Rat Hearts', \"Newcomb's Measurements of the Passage Time of Light\", 'Eighth-Grade Pupils in the Netherlands', 'Classical N, P, K Factorial Experiment', 'US Naval Petroleum Reserve No. 1 data', 'Data from an Oats Field Trial', \"The Painter's Data of de Piles\", \"N. L. Prater's Petrol Refinery Data\", 'Absenteeism from School in Rural New South Wales', 'Road Accident Deaths in US States', 'Numbers of Rotifers by Fluid Density', 'Ships Damage Data', 'Percentage of Shrimp in Shrimp Cocktail', 'Space Shuttle Autolander Problem', 'Snail Mortality Data', 'The Saturated Steam Pressure Data', 'The Stormer Viscometer Data', 'Student Survey Data', 'Synthetic Classification Problem', 'Synthetic Classification Problem', 'Spatial Topographic Data', 'Counts of Waders at 15 Sites in South Africa', \"House Insulation: Whiteside's Data\", 'Weight Loss Data from an Obese Patient', 'Cigarette Consumption', 'Crime in North Carolina', 'Employment and Wages in the United Kingdom', 'Gasoline Consumption', \"Grunfeld's Investment Data\", 'Hedonic Prices of Census Tracts in the Boston Area', 'Wages and Hours Worked', 'Wages and Education of Young Males', 'US States Production', 'Employment and Wages in Spain', 'The Penn World Table, v. 5', 'Panel Data of Individual Wages', 'Yearly batting records for all major league baseball players', 'Political opinion polls in Australia, 2004-07', 'elections to Australian House of Representatives, 1949-2007', 'Batting Averages for 18 major league baseball players, 1970', 'Voter turnout experiment, using Rock The Vote ads', '1992 United Kingdom electoral returns', 'Absentee and Machine Ballots in Pennsylvania State Senate Races', 'Applications to a Political Science PhD Program', 'article production by graduate students in biochemistry Ph.D. programs', 'California Congressional Districts in 2006', 'U.S. Senate vote on the use of force against Iraq, 2002.', 'Interviewer ratings of respondent levels of political information', 'elections for U.S. President, 1932-2012, by state', 'Prussian army horse kick data', 'cross national rates of trade union density', 'Reports of voting in the 1992 U.S. Presidential election.', 'Sensory data from a french fries experiment.', 'Demo data describing the Smiths.', 'Tipping data', \"Automobile Data from 'Consumer Reports' 1990\", \"Automobile Data from 'Consumer Reports' 1990\", \"Automobile Data from 'Consumer Reports' 1990\", 'Data on Children who have had Corrective Spinal Surgery', 'Soldering of Components on Printed-Circuit Boards', 'Stage C Prostate Cancer', 'US Expenditures for Public Schools', \"Bollen's Data on Industrialization and Political Democracy\", 'Variables from the 1997 Canadian National Election Study', \"Klein's Data on the U. S. Economy\", 'Partly Artificial Data on the U. S. Economy', 'Six Mental Tests', 'Bladder Cancer Recurrences', 'NCCTG Lung Cancer Data', 'Chronic Granulotomous Disease data', 'Chemotherapy for Stage B/C colon cancer', 'Assay of serum free light chain for 7874 subjects.', 'Stanford Heart Transplant data', 'Kidney catheter data', 'Acute Myelogenous Leukemia survival data', 'Data from the 1972-78 GSS data used by Logan', 'NCCTG Lung Cancer Data', 'Monoclonal gammapothy data', \"Data from the National Wilm's Tumor Study\", 'Ovarian Cancer Survival Data', 'Mayo Clinic Primary Biliary Cirrhosis Data', 'Rat treatment data from Mantel et al', 'More Stanford Heart Transplant data', \"Tobin's Tobit data\", \"Veterans' Administration Lung Cancer study\", 'Arthritis Treatment Data', 'Baseball Data', 'Broken Marriage Data', 'Ergebnisse der Fussball-Bundesliga', 'Votes in German Bundestag Election 2005', 'Butterfly Species in Malaya', 'Breathlessness and Wheeze in Coal Miners', 'Danish Welfare Study Data', 'Employment Status', \"'May' in Federalist Papers\", 'Hitters Data', 'Death by Horse Kicks', 'Hospital data', 'Job Satisfaction Data', 'Opinions About Joint Sports', 'Lifeboats on the Titanic', 'Non-Response Survey Data', 'Ovary Cancer Data', 'Pre-marital Sex and Divorce', 'Corporal Punishment Data', 'Repeat Victimization Data', 'Families in Saxony', 'Sex is Fun', 'Space Shuttle O-ring Failures', 'Suicide Rates in Germany', 'Truck Accidents Data', 'UK Soccer Scores', 'Visual Acuity in Left and Right Eyes', 'Von Bortkiewicz Horse Kicks Data', \"Weldon's Dice Data\", 'Women in Queues', 'Table of links for Zelig', 'Political Economic Risk Data from 62 Countries in 1987', 'U.S. Supreme Court Vote Matrix', '1932 Weimar election data', 'Table of links for Zelig', 'U.S. Presidential Approval Data', 'Sample data for bivariate probit regression', 'Coalition Dissolution in Parliamentary Democracies', 'Coalition Dissolution in Parliamentary Democracies, Modified Version', 'Simulation Data for Ecological Inference', 'Freedom of Speech Data', 'Freedom of Speech Data', 'Simulated Example of Schoolchildren Friendship Network', 'Simulation Data for model Seemingly Unrelated Regression (sur) that corresponds to method SUR of systemfit', 'Social Security Expenditure Data', 'Sample Data on Home Runs Hit By Mark McGwire and Sammy Sosa in 1998.', 'Individual Preferences Over Immigration Policy', 'Individual Preferences Over Immigration Policy', 'Individual Preferences Over Immigration Policy', 'Individual Preferences Over Immigration Policy', 'Individual Preferences Over Immigration Policy', 'Individual Preferences Over Immigration Policy', 'Simulation Data for model Two-Stage Least Square (twosls) that corresponds to method 2SLS of systemfit', 'Simulation Data for model Three-Stage Least Square (threesls) that corresponds to method 3SLS of systemfit', 'Macroeconomic Data', 'Voting Data from the 1988 Mexican Presidental Election', 'Militarized Interstate Disputes', \"The Discretized Painter's Data of de Piles\", 'Multilateral Economic Sanctions', 'Simulated Example of Social Network Data', 'Swiss Fertility and Socioeconomic Indicators (1888) Data', \"Tobin's Tobit Data\", 'Turnout Data Set from the National Election Survey', 'Sample Turnout and Demographic Data from the 2000 Current Population Survey', 'BCG Vaccine Data', 'Beat the Blues Data', 'CYG OB1 Star Cluster Data', \"The Forbes 2000 Ranking of the World's Biggest Companies (Year 2004)\", 'General Health Questionnaire', 'Prevention of Gastointestinal Damages', 'Total Body Composision Data', 'Aspirin Data', 'Birth and Death Rates Data', 'Bladder Cancer Data', 'Cloud Seeding Data', 'Epilepsy Data', 'Foster Feeding Experiment', 'Olympic Heptathlon Seoul 1988', 'Survival Times after Mastectomy of Breast Cancer Patients', 'Meteorological Measurements for 11 Years', 'Oral Lesions in Rural India', 'Phosphate Level Data', 'Piston Rings Failures', 'Exoplanets Data', 'Blood Screening Data', 'Familial Andenomatous Polyposis', 'Familial Andenomatous Polyposis', 'Romano-British Pottery Data', 'Rearrests of Juvenile Felons', 'Respiratory Illness Data', 'Students Estimates of Lecture Room Width', 'Age of Onset of Schizophrenia Data', 'Schizophrenia Data', 'Days not Spent at School', 'Egyptian Skulls', 'Nicotine Gum and Smoking Cessation', 'Student Risk Taking', 'Crowd Baiting Behaviour and Suicides', 'Toothpaste Data', 'House of Representatives Voting Data', 'Mortality and Water Hardness', 'Water Voles Data', 'Electricity from Wave Power at Sea', 'Gain in Weight of Rats', 'Womens Role in Society', 'Seven data sets showing a bifactor solution.', 'Seven data sets showing a bifactor solution.', 'Seven data sets showing a bifactor solution.', '8 cognitive variables used by Dwyer for an example.', 'Example data from Gleser, Cronbach and Rajaratnam (1965) to show basic principles of generalizability theory.', 'Example data set from Gorsuch (1997) for an example factor extension.', '5 socio-economic variables from Harman (1967)', 'Correlations of eight physical variables (from Harman, 1966)', 'Eight political variables used by Harman (1967) as example 8.17', 'Seven data sets showing a bifactor solution.', 'Seven data sets showing a bifactor solution.', 'Seven data sets showing a bifactor solution.', '12 variables created by Schmid and Leiman to show the Schmid-Leiman Transformation', 'Seven data sets showing a bifactor solution.', 'Seven data sets showing a bifactor solution.', '9 Cognitive variables discussed by Tucker and Lewis (1973)', '16 ability items scored as correct or incorrect.', 'Two data sets of affect and arousal scores as a function of personality and movie conditions', '25 Personality items representing 5 factors', '25 Personality items representing 5 factors', \"Bond's Logical Operations Test - BLOT\", '11 emotional variables from Burt (1915)', 'Distances between 11 US cities', \"Galton's example of the relationship between height and 'cubit' or forearm length\", 'A data set from Cushny and Peebles (1905) on the effect of three drugs on hours of sleep, used by Student (1908)', 'Eysenck Personality Inventory (EPI) data for 3570 participants', '13 personality scales from the Eysenck Personality Inventory and Big 5 inventory', 'Eysenck Personality Inventory (EPI) data for 3570 participants', \"Galton's Mid parent child height data\", 'A data.frame of the Galton (1888) height and cubit data set.', 'US family income from US census 2008', '16 multiple choice IQ items', '75 mood items from the Motivational State Questionnaire for 3896 participants', 'NEO correlation matrix from the NEO_PI_R manual', \"Galton's Peas\", '3 Measures of ability: SATV, SATQ, ACT', 'An example of the distinction between within group and between group correlations', 'Boscovich Data', 'Cobar Ore data', 'Garland(1983) Data on Running Speed of Mammals', 'Barro Data', 'Engel Data', 'UIS Drug Treatment study data', 'Growth curves of pigs in a 3x3 factorial experiment', 'Ordinal Data from Koch', 'Ohio Children Wheeze Status', 'Clustered Ordinal Respiratory Disorder', 'Data from a clinical trial comparing two treatments for a respiratory illness', 'Epiliptic Seizures', 'Growth of Sitka Spruce Trees', 'Log-size of 79 Sitka spruce trees', 'Liver related laboratory data', 'Rain, wavesurge and portpirie datasets.', 'Rain, wavesurge and portpirie datasets.', 'Air pollution data, separately for summer and winter months', 'Rain, wavesurge and portpirie datasets.', 'Air pollution data, separately for summer and winter months', 'Rheumatoid Arthritis Clinical Trial', 'Homeless Data', 'Daily Log Returns on BMW Share Price', 'Danish Fire Insurance Claims', 'The River Nidd Data', 'The River Nidd Data', 'Daily Log Returns on Siemens Share Price', 'SP Data to June 1993', 'SP Return Data to October 1987', 'Yield of dyestuff by batch', 'Yield of dyestuff by batch', 'University Lecture/Instructor Evaluations by Students at ETH', 'Paste strength by batch and cask', 'Variation in penicillin testing', 'Verbal Aggression item responses', 'Breakage Angle of Chocolate Cakes', 'Contagious bovine pleuropneumonia', 'Data on red grouse ticks from Elston et al. 2001', 'Reaction times in a sleep deprivation study']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# potential code before try catch\n",
        "\n",
        "try:\n",
        "    # code to try to execute\n",
        "except ZeroDivisionError:\n",
        "    # code to execute if there is a ZeroDivisionError\n",
        "except NameError:\n",
        "    # code to execute if there is a NameError\n",
        "except:\n",
        "    # code to execute if ther is any exception\n",
        "else:\n",
        "    # code to execute if there is no exception\n",
        "finally:\n",
        "    # code to execute at the end of the try except no matter what\n",
        "\n",
        "# code that will execute if there is no exception or a one that we are handling"
      ],
      "metadata": {
        "id": "cUMFISOPZU-b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://docs.python.org/3/library/itertools.html\n",
        "from itertools import cycle, repeat\n",
        "from time import sleep\n",
        "\n",
        "#for frame in cycle(r'-\\|/-\\|/'):\n",
        "for frame in repeat(r'-\\|/-\\|/', 100):\n",
        "    print('\\r', frame, sep='', end='', flush=True)\n",
        "    sleep(0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zLdL43DvgmeI",
        "outputId": "b3e07333-942f-4d5b-bb48-0c07a6edc199"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-\\|/-\\|/"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from time import sleep\n",
        "\n",
        "def progress(percent=0, width=30):\n",
        "    left = width * percent // 100\n",
        "    right = width - left\n",
        "    print('\\r[', '#' * left, ' ' * right, ']',\n",
        "          f' {percent:.0f}%',\n",
        "          sep='', end='', flush=True)\n",
        "\n",
        "for i in range(101):\n",
        "    progress(percent=i)\n",
        "    sleep(0.1)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9v3Vy900WBt7",
        "outputId": "fd565792-8a6e-44bb-eaf5-a0232f8ac36e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[##############################] 100%"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from time import sleep\n",
        "\n",
        "def progre(i):\n",
        "    print('\\r', i, sep='', end='', flush=True)\n",
        "\n",
        "for i in range(101):\n",
        "    progre(str(i)+\"%\")\n",
        "    sleep(0.25)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sPuzt05ohtGn",
        "outputId": "a53ddc5e-92c5-4bf9-ce48-ef69a32479f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100%"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Itertools"
      ],
      "metadata": {
        "id": "5eo7BXoAvLgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# https://docs.python.org/3/library/itertools.html\n",
        "# https://blog.quantinsti.com/itertools/\n",
        "\n",
        "import itertools as itt\n",
        "\n",
        "print('iteradores infinitos\\n')\n",
        "#Count\n",
        "print(\"count\")\n",
        "for _ in itt.count(10):\n",
        "  print(str(_))\n",
        "  if _>15:\n",
        "    break\n",
        "\n",
        "# cycle\n",
        "print(\"\\ncycle\")\n",
        "c=1\n",
        "for _ in itt.cycle(r'-\\|/-\\|/'):\n",
        "  print('\\r', _, sep='', end='', flush=True)\n",
        "  sleep(0.2)\n",
        "  if c>30:\n",
        "    break\n",
        "  c+=1\n",
        "\n",
        "# repeat\n",
        "print('\\n repeat')\n",
        "for _ in repeat('ABC', 10):\n",
        "  print(_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "386Qw0xmvKsp",
        "outputId": "d2f9c463-023d-4f32-ae6f-5b71dcc06a67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iteradores infinitos\n",
            "\n",
            "count\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "\n",
            "cycle\n",
            "|\n",
            " repeat\n",
            "ABC\n",
            "ABC\n",
            "ABC\n",
            "ABC\n",
            "ABC\n",
            "ABC\n",
            "ABC\n",
            "ABC\n",
            "ABC\n",
            "ABC\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing libraries\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "\n",
        "# Import Tesla data\n",
        "tesla = yf.download('TSLA','2020-03-01', '2020-03-30')\n",
        "tesla['daily_returns'] = tesla['Close'].pct_change()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9cqkG7VEFRE3",
        "outputId": "0a0b8383-c997-4506-83e0-ab318ff7d9b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r[*********************100%%**********************]  1 of 1 completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools as itt\n",
        "\n",
        "print('Iteradores que terminan\\n')\n",
        "#accumulate\n",
        "print('accumulate')\n",
        "for _ in itt.accumulate([1,2,3,4,5]) :\n",
        "  print(_, end=' ')\n",
        "#batched\n",
        "#print('\\nbatched') # desde version 3.12\n",
        "#for _ in itt.batched([1,2,3,4,5,6,7,8,9,10], 3) :\n",
        "#  print(_)\n",
        "\n",
        "stocks_NYSE = ['TSLA', 'MSFT', 'NVDA', 'GOOGL' , 'AAPL' , 'INTC']\n",
        "stocks_NSE = ['HDFC', 'RELIANCE', 'INFY', 'ICICIBANK']\n",
        "\n",
        "# Chain() itertool\n",
        "print('\\nchain')\n",
        "\n",
        "\n",
        "result = itt.chain(stocks_NYSE, stocks_NSE)\n",
        "for each in result:\n",
        "    print(each, end=' ')\n",
        "\n",
        "# Compress() itertool\n",
        "print('\\ncompress')\n",
        "selections = [1,0,0,1,0,1]\n",
        "result = itt.compress(stocks_NYSE, selections)\n",
        "for each in result:\n",
        "    print(each, end=' ')\n",
        "\n",
        "#dropwhile\n",
        "print('\\ndropwhile')\n",
        "for _ in itt.dropwhile(lambda x: x<5, [1,4,6,4,1]):\n",
        "  print(_, end=' ')\n",
        "\n",
        "#takewhile\n",
        "print('\\ntakewhile')\n",
        "for _ in itt.takewhile(lambda x: x<5, [1,4,6,4,1]):\n",
        "  print(_, end=' ')\n",
        "\n",
        "# filterfalse\n",
        "print('\\nfilterfalse')\n",
        "for _ in itt.filterfalse(lambda x: x%3, range(11)):\n",
        "  print(_, end=' ')\n",
        "\n",
        "# Islice() itertool\n",
        "print('\\nislice')\n",
        "selection = itt.islice(stocks_NYSE, 0, 15,2)\n",
        "for each in selection:\n",
        "    print(each, end=' ')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQ3ZYOD_xciV",
        "outputId": "c8cb8de5-70be-4705-9920-3ac594bb7ba6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteradores que terminan\n",
            "\n",
            "accumulate\n",
            "1 3 6 10 15 \n",
            "chain\n",
            "TSLA MSFT NVDA GOOGL AAPL INTC HDFC RELIANCE INFY ICICIBANK \n",
            "compress\n",
            "TSLA GOOGL INTC \n",
            "dropwhile\n",
            "6 4 1 \n",
            "takewhile\n",
            "1 4 \n",
            "filterfalse\n",
            "0 3 6 9 \n",
            "islice\n",
            "TSLA NVDA AAPL "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Logging\n",
        "\n",
        "Permite hacer log dentro de la programacion"
      ],
      "metadata": {
        "id": "Ogjo-w8etDhf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "\n",
        "\n",
        "logging.basicConfig(filename='mi_log.txt',\n",
        "                    level=logging.INFO,\n",
        "                    format='%(asctime)s - %(levelname)s - %(message)s',\n",
        "                    datefmt='%Y-%m-%d %I:%M:%S %p',  # Formato de fecha y hora\n",
        "                    filemode='a')  # 'a' para agregar al archivo\n",
        "\n",
        "\n",
        "logging.info(\"Comienzo del procesamiento\")\n",
        "\n",
        "logging.warning(\"esto es un warning\")\n",
        "\n",
        "logging.info(bd_vector.head())\n",
        "\n",
        "logging.info(bd_vector.describe())\n",
        "\n",
        "\n",
        "\n",
        "logging.shutdown() # Para cerrar el archivo"
      ],
      "metadata": {
        "id": "OPyZqsQVtMM3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}